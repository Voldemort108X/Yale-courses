{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skEYZi0VpZVV"
      },
      "source": [
        "# Intermediate Machine Learning: Assignment 4\n",
        "\n",
        "**Deadline**\n",
        "\n",
        "Assignment 4 is due Wednesday, April 27 by 11:59pm. Late work will not be accepted as per the course policies (see the Syllabus and Course policies on Canvas).\n",
        "\n",
        "Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged.\n",
        "\n",
        "You should start early so that you have time to get help if you're stuck. The drop-in office hours schedule can be found on Canvas. You can also post questions or start discussions on Ed Discussion. The assignment may look long at first glance, but the problems are broken up into steps that should help you to make steady progress.\n",
        "\n",
        "**Submission**\n",
        "\n",
        "Submit your assignment as a pdf file on Gradescope, and as a notebook (.ipynb) on Canvas. You can access Gradescope through Canvas on the left-side of the class home page. The problems in each homework assignment are numbered. Note: When submitting on Gradescope, please select the correct pages of your pdf that correspond to each problem. This will allow graders to more easily find your complete solution to each problem.\n",
        "\n",
        "To produce the .pdf, please do the following in order to preserve the cell structure of the notebook:\n",
        "\n",
        "Go to \"File\" at the top-left of your Jupyter Notebook\n",
        "Under \"Download as\", select \"HTML (.html)\"\n",
        "After the .html has downloaded, open it and then select \"File\" and \"Print\" (note you will not actually be printing)\n",
        "From the print window, select the option to save as a .pdf\n",
        "\n",
        "**Topics**\n",
        "\n",
        " * Graph kernels\n",
        " * Reinforcement learning\n",
        " * Recurrent neural networks\n",
        "\n",
        "This assignment will also help to solidify your Python skills."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6CLfH3SpZVX"
      },
      "source": [
        "<!-- $\\renewcommand{\\reals}{{\\mathbb R}}\n",
        "\\newcommand{\\indp}{\\perp\\kern-4pt\\perp}\n",
        "\\newcommand{\\given}{\\,|\\,}\n",
        "$ -->\n",
        "\n",
        "## Problem 1: Graph kernels (10 points)\n",
        "\n",
        "The graph Laplacian for a weighted graph on $n$ nodes is defined as\n",
        "\n",
        "$$ L = D - W$$\n",
        "\n",
        "where $W$ is an $n\\times n$ symmetric matrix of positive edge weights,\n",
        "with $W_{ij} = 0$ if $(i,j)$ is not an edge in the graph,\n",
        "and $D$ is the diagonal matrix with $D_{ii} = \\sum_{j=1}^n W_{ij}$.\n",
        "This generalizes the definition of the Laplacian\n",
        "used in class, where all of the edge weights are one.\n",
        "\n",
        "\n",
        "1. Show that $L$ is a Mercer kernel, by showing that $L$ is\n",
        "  symmetric and positive-semidefinite.\n",
        "<br>\n",
        "\n",
        "Answer:\n",
        "We first show that $L$ is a symmetric matrix. As we have\n",
        "\\begin{align}\n",
        "  L &= D - W \\\\\n",
        "    &= D^T - W^T \\\\\n",
        "    &= L^T.\n",
        "\\end{align}\n",
        "For any vector $x=[x_1,...,x_n]^T$, we have\n",
        "\\begin{align}\n",
        "  x^TLx &= \\sum_{i=1}^n\\left(x_i^2\\sum_{j=1}^nW_{ij}-x_i\\sum_{j=1}^nx_jW_{ji} \\right) \\\\\n",
        "        &= \\sum_{i\\neq j}(x_i-x_j)^2W_{ij} \\\\\n",
        "        &\\geq 0 \n",
        "\\end{align}\n",
        "given $W_{ij}\\geq 0$. Thus $L$ is a symmetric and positive-semidefinite matrix, which shows that $L$ is a Mercer kernel.\n",
        "\n",
        "2. In graph neural networks we define polynomial filters of the form\n",
        "\n",
        "  $$ P = a_0 I + a_1 L + a_2 L^2 + \\cdots a_d L^d$$\n",
        "  \n",
        "  where $L$ is the Laplacian and $a_0,\\ldots, a_d$ are parameters,\n",
        "  corresponding to the filter parameters in standard convolutional\n",
        "  neural networks.\n",
        "\n",
        "  If each $a_i \\geq 0$ is non-negative, show that $P$ is also\n",
        "  a Mercer kernel. \n",
        "<br>\n",
        "\n",
        "Answer: \n",
        "For each term in the polynomial, we have\n",
        "\\begin{align}\n",
        "  x^Ta_iL^ix = \n",
        "  \\begin{cases}\n",
        "    a_i(xL^k)^TLxL^k\\geq 0 & i=2k+1 \\\\\n",
        "    a_i\\|xL^k\\|^2\\geq 0 & i=2k\n",
        "  \\end{cases}\n",
        "\\end{align}\n",
        "for any $x\\in\\mathbb{R}^n$. As each term in $P$ is symmetric as shown in (1), $P$ is a symmetric and positive semi-definite matrix, which is also a Mercer kernel.\n",
        "\n",
        "3. Is positivity of the coefficients $a_i$ a necessary condition? Explain.\n",
        "\n",
        "Answer: \n",
        "The positivity of the coefficients is not a necessary condition as we only need the sum of the quadratic term to be greater than zero for any $x$. The positivity of the coefficients $a_i$ is a sufficient condition.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_S3-h_-pZVY"
      },
      "source": [
        "\n",
        "##  Problem 2:  Positive reinforcement  (10 points)\n",
        "<!-- $\\def\\J{{\\mathcal J}}$\n",
        "$\\def\\E{{\\mathbb E}}$ -->\n",
        "\n",
        "As discussed in class, reinforcement learning\n",
        "using policy gradient methods is based on maximizing the\n",
        "expected total reward\n",
        "\n",
        "$$ \\mathcal{J}(\\theta) = \\mathbb{E}_\\theta [R(\\tau)],$$\n",
        "\n",
        "where the expectation is over the probability distribution over sequences $\\tau$ through a choice of actions using the policy. This can be rewritten as\n",
        "\n",
        "\\begin{align*}\n",
        "  \\nabla_\\theta \\mathcal{J}(\\theta) & = \\mathbb{E}_\\theta\\left[ R(\\tau) \\nabla_\\theta \\log p(\\tau\\,|\\, \\theta) \\right].\n",
        "\\end{align*}\n",
        "\n",
        "Approximating this gradient involves computing $\\nabla_\\theta \\log \\pi_\\theta (a\\,|\\, s)$ where $\\pi_\\theta$ is the policy.\n",
        "\n",
        "Suppose that the action space is continuous\n",
        "and $\\pi_\\theta(a\\,|\\, s)$ is a normal density with mean\n",
        "$\\mu_\\theta(s)$ and variance $\\sigma^2_\\theta(s)$, two outputs of\n",
        "a neural network with input $s$ and parameters $\\theta$.\n",
        "\n",
        "1. Suppose the outputs of the neural network are given by\n",
        "\n",
        "\\begin{align*}\n",
        "  \\mu_\\theta(s) & = \\beta_1^T h(s) \\\\\n",
        "  \\sigma^2_\\theta(s) &= \\text{sigmoid}(\\beta_2^T h(s))\n",
        "\\end{align*}\n",
        "\n",
        "where $h(s)$ is the vector of neurons in the last layer, immediately\n",
        "before the outputs. Derive explicit expressions for\n",
        "$\\nabla_{\\beta_1} \\log \\pi_\\theta(a\\,|\\, s)$ and\n",
        "$\\nabla_{\\beta_2} \\log \\pi_\\theta(a\\,|\\, s)$.\n",
        "\n",
        "Answer:\n",
        "To compute the gradients, we first have\n",
        "\\begin{align}\n",
        "  \\log\\pi_\\theta(a|s) &= \\log\\frac{1}{\\sqrt{2\\pi}\\sigma(s)}e^{-\\frac{(a-\\mu(s))^2}{2\\sigma^2(s)}} \\\\\n",
        "                      &= -\\log\\sqrt{2\\pi}\\sigma(s) - \\frac{(a-\\mu(s))^2}{2\\sigma^2(s)}\n",
        "\\end{align}\n",
        "\n",
        "and then we have\n",
        "\\begin{align}\n",
        "  \\nabla_{\\beta_1}\\log\\pi_\\theta(a|s) &= -\\frac{\\mu(s)-a}{\\sigma^2(s)}\\nabla_{\\beta_1}\\mu(s) \\\\\n",
        "                                      &= -\\frac{\\mu(s)-a}{\\sigma^2(s)}h(s) \\\\\n",
        "                                      &= -\\frac{\\beta_1^T h(s)-a}{\\text{sigmoid}(\\beta_2^T h(s))}h(s)\n",
        "\\end{align}\n",
        "\\begin{align}\n",
        "  \\nabla_{\\beta_2}\\log\\pi_\\theta(a|s) &= \\left(-\\frac{1}{\\sigma(s)} + \\frac{(a-\\mu(s))^2}{\\sigma(s)^3} \\right)\\nabla_{\\beta_2}\\sigma(s) \\\\\n",
        "                                      &= \\left(-\\frac{1}{\\sigma(s)} + \\frac{(a-\\mu(s))^2}{\\sigma(s)^3} \\right)\\sigma^2(s)h(s) \\\\\n",
        "                                      &= \\left(-\\text{sigmoid}(\\beta_2^T h(s)) + \\frac{(a-\\beta_1^T h(s))^2}{\\text{sigmoid}(\\beta_2^T h(s))} \\right)h(s)\n",
        "\\end{align}\n",
        "<br>\n",
        "\n",
        "2. Explain how these gradients and other gradient\n",
        "terms in $\\nabla_\\theta \\log \\pi_\\theta(a\\,|\\, s)$ are used\n",
        "to estimate the policy.\n",
        "\n",
        "Answer:\n",
        "We parameterize the policy as $\\pi_\\theta(a|s)$ and use the gradient ascent on the loss function to estimate the policy. As we can use the total expected reward as the loss, we have\n",
        "\\begin{align}\n",
        "  \\mathcal{L}(\\theta) &= \\mathbb{E}_\\theta(R(\\tau)) \\\\\n",
        "                      &= \\int p(\\tau|\\theta)R(\\tau)d\\tau.\n",
        "\\end{align}\n",
        "From the lecture slides, we can approximate the gradient by\n",
        "\\begin{align}\n",
        "  \\nabla_\\theta\\mathcal{L}(\\theta) &\\approx \\frac{1}{N}\\sum_{i=1}^NR(\\tau^{(i)})\\nabla_\\theta\\log p(\\tau^{(i)}|\\theta) \\\\\n",
        "                                   &= \\frac{1}{N}\\sum_{i=1}^NR(\\tau^{(i)})\\sum_{t=0}^T\\nabla_\\theta\\log\\pi_\\theta(a_t^{(i)}|s_t^{(i)}).\n",
        "\\end{align}\n",
        "The parameters of policy gradient are then updated iteratively by \n",
        "\\begin{align}\n",
        "  \\theta \\leftarrow \\theta + \\eta\\hat{\\nabla_\\theta\\mathcal{L}(\\theta)}.\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_P2Vw1WpZVY"
      },
      "source": [
        "## Problem 3: Deep Q-Learning for Flappy Bird (25 points)\n",
        "\n",
        "Deep Q-learning was proposed (and patented) by DeepMind and made \n",
        "a big splash when the same deep neural network architecture was shown to be able to surpass\n",
        "human performance on many different Atari games, playing directly from the pixels.\n",
        "In this problem, we will walk you through the implementation of deep Q-learning \n",
        "to learn to play the Flappy Bird game.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/YData123/sds365-sp22/main/assignments/assn4/images/flappy_bird_demp.gif\" width=\"144\" height=\"256\"/>\n",
        "\n",
        "The implementation is based these references:\n",
        "- [DeepLearningFlappyBird](https://github.com/yenchenlin/DeepLearningFlappyBird)\n",
        "- [Deep Q-Learning for Atari Breakout](https://keras.io/examples/rl/deep_q_network_breakout/)\n",
        "\n",
        "We use the `pygame` package to visualize the interaction between the algorithm \n",
        "and the game environment. \n",
        "However, _pygame_ is not well supported by Google Colab; \n",
        "we recommend you to run the code for this problem locally.\n",
        "A window will be popped up that displays\n",
        "the game as it progress in real-time (as for the Cartpole demo from class).\n",
        "\n",
        "This problem is structured as follows:\n",
        "\n",
        "* Load necessary packages\n",
        "* Test the visualization of the game, to make sure everything's working\n",
        "* Process the images to reduce the dimension\n",
        "* Setup the game history buffer \n",
        "* Implement the core Q-learning function\n",
        "* Run the learning algorithm\n",
        "* Interpret the results\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCI6IeIVpZVZ"
      },
      "source": [
        "### Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm04pJZYpZVZ"
      },
      "source": [
        "Please make sure that the following files are in the same place:\n",
        "- assn4.ipynb\n",
        "- wrapped_flappy_bird.py\n",
        "- flappy_bird.utils.py\n",
        "- assets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmnAGJ1jpZVZ"
      },
      "source": [
        "If you do use Google Colab, set `using_colab` to be *True* in the following cell.\n",
        "If you access extra files through Google Drive, then uncomment the `'%cd ...'` \n",
        "line and change `PATH` to where you store the files on your Google Drive (need not to do this if you are using the temporary files for Colab)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fD9lkzwmpZVZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# from google.colab.patches import cv2_imshow\n",
        "# from google.colab import output\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "using_colab = True\n",
        "\n",
        "if using_colab:\n",
        "    os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
        "    # %cd /content/drive/MyDrive/PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wIDYK6ZpZVa"
      },
      "source": [
        "The Flappy Bird game requires a few Python packages. Please install these _as soon as possible_, and notify us of any issues you experience so that we can help. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Sd6cDbOOpZVa",
        "outputId": "0b393c5d-a71e-4c46-8efb-72a77f0fe398"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pygame 2.1.2 (SDL 2.0.16, Python 3.6.13)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ]
        }
      ],
      "source": [
        "# %pip install pygame\n",
        "# %pip install opencv-python\n",
        "import numpy as np\n",
        "import cv2\n",
        "import wrapped_flappy_bird as flappy_bird\n",
        "from collections import deque\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, initializers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfK-OPrIpZVb"
      },
      "source": [
        "### The Flappy Bird environment \n",
        "\n",
        "Interaction with the game environment is carried out through calls of the form\n",
        "\n",
        "`(image, reward, terminal) = game.frame_step(action)`\n",
        "\n",
        "where the meaning of these variables is as follows:\n",
        "\n",
        "- `action`: $\\binom{1}{0}$ for doing nothing, $\\binom{0}{1}$ for \"flapping the bird's wings\"\n",
        "- `image`: the image for the next step of the game, of size $(288, 512, 3)$ with three RGB channels\n",
        "- `reward`: the reward received for taking the action; -1 if an obstacle is hit, 0.1 otherwise. \n",
        "- `terminal`: `True` if an obstacle is hit, otherwise `False`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiKLJFh9pZVb"
      },
      "source": [
        "Now let's take a look at the game interface.\n",
        "First, initiate the game:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fpvkvwDTpZVb",
        "outputId": "b550d342-e348-457e-830a-c208e40c63b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape of image: (288, 512, 3)\n",
            "reward:  0.1\n",
            "terminal:  False\n"
          ]
        }
      ],
      "source": [
        "num_actions = 2\n",
        "\n",
        "# initiate a game\n",
        "game = flappy_bird.GameState()\n",
        "\n",
        "# get the first state by doing nothing\n",
        "do_nothing = np.zeros(num_actions)\n",
        "do_nothing[0] = 1\n",
        "image, reward, terminal = game.frame_step(do_nothing)\n",
        "\n",
        "print('shape of image:', image.shape)\n",
        "print('reward: ', reward)\n",
        "print('terminal: ', terminal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frqX679MpZVb"
      },
      "source": [
        "After (locally) running the above cells, a window should pop up, and you can watch the game being played in that window. \n",
        "\n",
        "Let's take some random actions and see what happens:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Oeq5hMNHpZVb",
        "outputId": "0706094a-79a2-4b87-a980-102bf0d5c3ba"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in range(587):\n",
        "    \n",
        "    # choose a random action \n",
        "    action = np.random.choice(num_actions)\n",
        "    \n",
        "    # create the corresponding one-hot vector\n",
        "    action_vec = np.zeros(num_actions)\n",
        "    action_vec[action] = 1\n",
        "\n",
        "    # take the action and observe the reward and the next state\n",
        "    image, reward, terminal = game.frame_step(action_vec)\n",
        "\n",
        "    # visualization on Colab\n",
        "    if using_colab and i % 3 == 0:\n",
        "        #  convert from (width, height, channel) to (height, width, channel)\n",
        "        view = image.transpose([1, 0, 2])\n",
        "\n",
        "        #  convert from rgb to bgr\n",
        "        img_bgr = cv2.cvtColor(view, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        #Display image, clear cell output\n",
        "        plt.imshow(img_bgr)\n",
        "        display.clear_output(wait=True)\n",
        "        display.display(plt.gcf())\n",
        "        # plt.clf()\n",
        "        # plt.imshow(img_bgr)\n",
        "        # output.clear(wait=True)\n",
        "        # cv2_imshow(img_bgr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTte6NpypZVb"
      },
      "source": [
        "Are you able to see Flappy moving across the window and crashing into things? Great! If you're \n",
        "having any issues, post to EdD and we'll do our best to help you out.\n",
        "\n",
        "Here is how we can visualize a frame of the game as an image within a cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KrF_X0S-pZVc",
        "outputId": "0c3e538d-258e-410e-c14c-338b9aff50c2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# show the image\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(image.transpose([1, 0, 2]))\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J-qmg2lpZVc"
      },
      "source": [
        "### Preprocessing the images \n",
        "\n",
        "Alright, next we need to prepocess the images by converting them to grayscale and resizing them to $80\\times 80$ pixels. This will help \n",
        "to reduce the computation, and aid learning. Besides, Flappy is \n",
        "\"color blind.\" (Fun fact: The instructor of this course is also \n",
        "[color vision deficient](https://en.wikipedia.org/wiki/Color_blindness).)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2gXTfaI5pZVc",
        "outputId": "a9267f78-e071-4950-bdb9-3e5915ddebd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of the transformed image: (80, 80, 1)\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPqklEQVR4nO3db2xVdZ7H8fenl5Z/ZcEKljKwq0akaoI4NqNGsrooE2fW6CYa4p+ZmIkJT9wNZmcyq+MjN9nEeTIjyW7GEHV2HrijwmgGCdFV1LCbbFhlcCNYEdASqRbKACnLYqXc7z64RywMtae9t/dPf59XcnPv+d3ee76Hw6fnnHtPz1cRgZlNfk21LsDMqsNhN0uEw26WCIfdLBEOu1kiHHazRJQVdkm3Sdotaa+kRypVlJlVnsb7PbukAvARsBI4ALwD3BsRH1SuPDOrlCllvPY7wN6I+BhA0vPAncCIYZfU0GfwzJgxg0WLFtHa2jqm1/X39/PZZ58xNDQ0QZWVRxLt7e10dHTQ1FRfR3aHDx+mt7e3bv/tamWkddbT08Phw4d13hdFxLhuwN3A08Omfwj88yiviUa6STrrdt1118XWrVtjLIaGhuKpp56K+fPnR/bLru5u06dPj8ceeyyOHz8+pmWbaKdPn45169bF/Pnza/5vVG+3kdbZtddeGzFC/srZsuciaTWweqLnU0lNTU1cccUVLF26lKlTp54Zv/TSS2lvbx/Te0liyZIlrFq1iv7+fnbs2MHu3bu/+uVnVjXlhL0XWDRsemE2dpaIWAesg8bZjS8UCixfvpw1a9Ywa9asM+NTp05l9uzZY3qvpqYmurq66Ozs5PDhwzz55JPs3bvXu6VWdeWE/R1gsaRLKIX8HuC+ilRVY5JobW2lo6ODOXPmlP1+ra2ttLa2MnXqVObOncvs2bMZHBzkiy++cOitasYd9ogYkvS3wGtAAXg2InZVrLJJaPr06axcuZK5c+fS29vL5s2b+eijj2pdliWirGP2iNgMbK5QLZPetGnTuOmmm1i+fDk7d+5k165dDrtVzYR/QNeIIoIjR46wZ88e2trazux6l6tYLHLkyBGOHTtGb28vJ0+erEC1Zvk47OcxNDTE1q1b6evro729nfvuu49bb70V6fxfX+Z14sQJNm7cyObNmzl69Ki36lZVDvt5RAT79u1j3759dHR0sHz5ciKi7LB/+eWXvP/++2zatIlTp05VqFqzfBz2UQwODrJz505ee+21ss8uGxgYYP/+/RSLxQpVZ5afwz6KgYEB1q9fzxtvvFH2exWLRQ4ePMjp06crUJnZ2DjsoxgaGqK3t5fe3j85X8isodTXXz2Y2YRx2M0S4bCbJcJhN0uEw26WCIfdLBEOu1kiHHazRDjsZolw2M0S4bCbJcJhN0vEqGGX9KykQ5J2Dhtrk/S6pD3Z/QUTW6aZlSvPlv1fgdvOGXsE2BIRi4Et2bSZ1bFRwx4RW4Ej5wzfCfwme/wb4G8qW5aZVdp4j9nbI+Lz7HEfMLY2KWZWdWVfvCIi4ps6vTRi+yezyWi8W/aDkjoAsvtDI/1gRKyLiK6I6BrnvMysAsYb9o3AA9njB4DfV6YcM5soeb56+y3wX8ASSQckPQg8AayUtAe4NZs2szo26jF7RNw7wlO3VLgWM5tAPoPOLBEOu1kiHHazRDjsZolw2M0S4bCbJcJhN0uEw26WCIfdLBEOu1kiHHazRDjsZolw2M0S4bCbJcJhN0uEw26WCIfdLBEOu1kiHHazROS54OQiSW9J+kDSLklrsnH3ezNrIHm27EPAjyPiSuB64CFJV+J+b2YNJU+vt88j4g/Z4+NAN/At3O/NrKGMqf2TpIuBa4Bt5Oz35vZPZvUh9wd0klqB3wEPR8TA8OciIoDz9ntz+yez+pAr7JKaKQX9uYh4KRvO3e/NzGpv1N14SQKeAboj4hfDnvqq39sTuN9bQzt9+jQ9PT28/fbbzJgxo9blnFEsFunu7mZwcLDWpUwKeY7ZbwR+CLwv6b1s7GeUQv5i1vttP7BqQiq0CXfq1Cm2bNnCzp07KRQKtS7njGKxyJEjRzh+/HitS5kU8vR6+09AIzztfm+TQETQ19dHX19frUuxCeQz6MwS4bCbJcJhN0uEw26WCIfdLBFjOl3WzOpDsVjk0KFD7Nq1i5kzZ54ZP3ny5IivcdjNGtCpU6d488036enpYcqUr2N84MCBEV+j0mnt1SGpejMzS1REnPe8GB+zmyXCYTdLhMNulgiH3SwRDrtZIhx2s0Q47GaJcNjNEuGwmyXCYTdLRJ72T9Mk/bek/8naPz2ejV8iaZukvZJekNQy8eWa2Xjl2bIPAisi4mpgGXCbpOuBnwO/jIjLgKPAgxNWpZmVLU/7p4iI/80mm7NbACuADdm42z+Z1bm8TSIK2WWkDwGvA/uAYxExlP3IAUr938732tWS3pX0bgXqNbNxyhX2iDgdEcuAhcB3gM68M3D7J7P6MKZP4yPiGPAWcAMwR9JXfzW/EOitbGlmVkl5Po2fJ2lO9ng6sJJS2+a3gLuzH3P7J7M6N+qVaiQtpfQBXIHSL4cXI+IfJV0KPA+0ATuAH0TENzbl8pVqzCbeSFeq8WWpzCYZX5bKLHEOu1kiHHazRDjsZolw2M0S4bCbJcJhN0uEw26WCIfdLBEOu1kiHHazRLg/u9HU1MTixYu5/PLLz+r1XQ8++eQTuru7GRz8xr+xshzqa81aTTQ3N7NixQpWr17NzJkza13OGcVikfXr17N27VqHvQIcdqOpqYm2tjYuu+wyWltba13OGcVikfb29rrb22hUPmY3S4TDbpYIh90sEQ67WSJyhz27dvwOSZuyabd/MmsgY9myr6F0VdmvuP2TWQPJ2xFmIfDXwNPZtHD7J7OGkvcLzCeBnwKzsukLGUP7J2B1GTWa2QhK292vfdPVokcNu6TbgUMRsV3SzWMtJiLWAeuy9/KlpM0qoFAocNVVV7F06dKzTjp65ZVXRnxNni37jcAdkr4PTAP+DFhL1v4p27q7/ZNZFTU3N3PzzTfz0EMPMWPGjDPj27dvH/E1o4Y9Ih4FHgXItuw/iYj7Ja2n1P7pedz+yayqJDFr1iwWLFhw1inOLS0jfylWzvfs/wD8vaS9lI7hnynjvcxsgo3pLwwi4m3g7ezxx5TaN5tZA/AZdGaJcNjNEuGwmyXCYTdLhMNulgiH3SwRDrtZIhx2s0Q47GaJcNjNEuGwmyXCYTdLhMNulgiH3SwRDrtZIhx2s0Q47GaJcNjNEpHrslSSeoDjwGlgKCK6JLUBLwAXAz3Aqog4OjFlmlm5xrJl/6uIWBYRXdn0I8CWiFgMbMmmzaxOlbMbfyeltk/g9k9mdS9v2AP4d0nbs3ZOAO0R8Xn2uA9or3h1ZlYxeS8lvTwieiVdBLwu6cPhT0ZEjNTayb3ezOpDri17RPRm94eAlyldL/6gpA6A7P7QCK9dFxFdw471zawGRg27pJmSZn31GPgusBPYSKntE7j9k1ndy7Mb3w68nLWGnQL8W0S8Kukd4EVJDwL7gVUTV6aZlStPY8ePgavPM/5H4JaJKMrMKs9n0JklwmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmiXDYzRLhsJslwmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmiXDYzRLhsJslwmE3S0SusEuaI2mDpA8ldUu6QVKbpNcl7cnuL5joYs1s/PJu2dcCr0ZEJ6Xr0XXj9k9mDSXPpaRnA38JPAMQEV9GxDHc/smsoeTZsl8C9AO/lrRD0tPZ9ePd/smsgeQJ+xTg28CvIuIa4ATn7LJHRFDqB/cnJK2W9K6kd8st1szGL0/YDwAHImJbNr2BUvjd/smsgYwa9ojoAz6VtCQbugX4ALd/Mmsoebu4/h3wnKQW4GPgR5R+Ubj9k1mDyBX2iHgPON9uuNs/mTWIvFv2iikUCtWepY2iUCjQ1FSfJ1NKolAo+P/NOcazzqoa9nnz5nHXXXdVc5aWQ0tLC11dXTQ3N9e6lLNIorOzk/vvv5+BgYFal1NXxrPOqhr2BQsW8Pjjj1dzlpaDJKZPn05LS0utSzmLJLq6uujs7KRYLNa6nLoynnVW1bBPmTKFiy66qJqztAY3bdo0pk2bVusyJoX6PFAzs4pz2M0S4bCbJcJhN0uEw26WCIfdLBEOu1kiHHazRDjsZolw2M0S4bCbJcJhN0uEw26WCIfdLBF5mkQskfTesNuApIfd/smsseS5uuzuiFgWEcuAa4H/A17G7Z/MGspYd+NvAfZFxH7c/smsoYw17PcAv80eu/2TWQPJHfbsmvF3AOvPfS5v+6f+/v5xF2pm5RnLlv17wB8i4mA2Peb2T/PmzSuvWjMbt7GE/V6+3oUHt38yayi5wp61aF4JvDRs+AlgpaQ9wK3ZtJnVqbztn04AF54z9kfc/smsYfgMOrNEOOxmiXDYzRLhsJslwmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmiXDYzRLhsJslwmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmiXDYzRLhsJslwmE3S4RKzVyqNDOpHzgBHK7aTKtrLpNz2bxcjeMvIuK83ViqGnYASe9GRFdVZ1olk3XZvFyTg3fjzRLhsJslohZhX1eDeVbLZF02L9ckUPVjdjOrDe/GmyWiqmGXdJuk3ZL2SnqkmvOuJEmLJL0l6QNJuyStycbbJL0uaU92f0Gtax0PSQVJOyRtyqYvkbQtW28vSGqpdY3jIWmOpA2SPpTULemGybLO8qha2CUVgH8BvgdcCdwr6cpqzb/ChoAfR8SVwPXAQ9myPAJsiYjFwJZsuhGtAbqHTf8c+GVEXAYcBR6sSVXlWwu8GhGdwNWUlnGyrLPRRURVbsANwGvDph8FHq3W/Cd42X5PqX/9bqAjG+sAdte6tnEsy0JK/+lXAJsAUTrxZMr51mOj3IDZwCdkn1MNG2/4dZb3Vs3d+G8Bnw6bPpCNNTRJFwPXANuA9oj4PHuqD2ivVV1leBL4KVDMpi8EjkXEUDbdqOvtEqAf+HV2iPK0pJlMjnWWiz+gK4OkVuB3wMMRMTD8uShtKhrqqw5JtwOHImJ7rWuZAFOAbwO/iohrKJ22fdYueyOus7GoZth7gUXDphdmYw1JUjOloD8XES9lwwcldWTPdwCHalXfON0I3CGpB3ie0q78WmCOpCnZzzTqejsAHIiIbdn0Bkrhb/R1lls1w/4OsDj7ZLcFuAfYWMX5V4wkAc8A3RHxi2FPbQQeyB4/QOlYvmFExKMRsTAiLqa0ft6MiPuBt4C7sx9ruOUCiIg+4FNJS7KhW4APaPB1NhbV/qu371M6JiwAz0bEP1Vt5hUkaTnwH8D7fH1s+zNKx+0vAn8O7AdWRcSRmhRZJkk3Az+JiNslXUppS98G7AB+EBGDNSxvXCQtA54GWoCPgR9R2uBNinU2Gp9BZ5YIf0BnlgiH3SwRDrtZIhx2s0Q47GaJcNjNEuGwmyXCYTdLxP8DCGfnJVq2R8kAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "def resize_gray(frame):\n",
        "    frame = cv2.cvtColor(cv2.resize(frame, (80, 80)), cv2.COLOR_BGR2GRAY)\n",
        "    ret, frame = cv2.threshold(frame, 1, 255, cv2.THRESH_BINARY)\n",
        "    return np.reshape(frame, (80, 80, 1))\n",
        "\n",
        "image_transformed = resize_gray(image)\n",
        "print('Shape of the transformed image:', image_transformed.shape)\n",
        "\n",
        "# show the transformed image\n",
        "_ = plt.imshow(image_transformed.transpose((1, 0, 2))[:, :, 0], cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rCUdv8RpZVc"
      },
      "source": [
        "This shows the preprocessed image for a single frame of\n",
        "the game. In our implementation of Deep Q-Learning, we encode the state by stacking four consecutive frames, resulting in \n",
        "a tensor of shape (80,80,4). \n",
        "\n",
        "Then, given the `current_state`, and a raw image `image_raw`\n",
        "of size $288\\times512\\times3$, we convert \n",
        "the raw image to a $80\\times80\\times 1$ grayscale image using the\n",
        "code in the previous cell. The , \n",
        "we remove the first frame of `current_state` and add \n",
        "the new frame, giving again a stack of images of \n",
        "size (80, 80, 4)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mgwUOO5DpZVc"
      },
      "outputs": [],
      "source": [
        "def preprocess(image_raw, current_state=None):\n",
        "    # resize and convert to grayscale\n",
        "    image = resize_gray(image_raw)\n",
        "    # stack the frames\n",
        "    if current_state is None:\n",
        "        state = np.concatenate((image, image, image, image), axis=2)\n",
        "    else:\n",
        "        state = np.concatenate((image, current_state[:, :, :3]), axis=2)\n",
        "    return state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnDEgieopZVc"
      },
      "source": [
        "### 3.1 Explain the game state\n",
        "\n",
        "Why is the state chosen to be a stack of four consecutive\n",
        "frames rather than a single frame? Give an intuitive explanation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xD8TQF4pZVc"
      },
      "source": [
        "Answer:\n",
        "Using a stack of 4 frames as input will catch more temporal information such as the velocity and acceleration, which will be helpful for the network optimization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_9VX1YHpZVc"
      },
      "source": [
        "###  Constructing the neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seL3JlxGpZVc"
      },
      "source": [
        "Now we are ready to construct the neural network for approximating the Q function. Recall that, given input $s$ which is of size $80\\times80\\times4$ due to the \n",
        "previous preprocessing, the output of the network should be of size 2, corresponding to the values of $Q(s,a_1)$ and $Q(s, a_2)$ respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRuZOkzCpZVd"
      },
      "source": [
        "Here is the summary of the model we'd like to build:\n",
        "\n",
        "<!-- ![Neural network](https://raw.githubusercontent.com/YData123/sds365-sp22/main/assignments/assn4/images/q_model.png) -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUWwcoRNpZVd"
      },
      "source": [
        "### 3.2 Initialize the network\n",
        "\n",
        "Complete the code in the next cell so that your model architecture matches that in the above picture. Here we specify the initialization of the weights by using `keras.initializers`.\n",
        "Note that we haven't talked about the `strides` argument for CNNs; \n",
        "you can read about stride here: [https://machinelearningmastery.com/padding-and-stride-for-convolutional-neural-networks/](https://machinelearningmastery.com/padding-and-stride-for-convolutional-neural-networks/). It's not important to understand this in detail, you just need to choose the number and sizes of the filters to get the shapes to match the specification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "F7Q-1gI0pZVd"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import initializers\n",
        "def create_q_model():\n",
        "    state = layers.Input(shape=(80, 80, 4,))\n",
        "\n",
        "    layer1 = layers.Conv2D(filters=32, kernel_size=5, strides=4, activation=\"relu\",\n",
        "                           kernel_initializer=initializers.TruncatedNormal(mean=0., stddev=0.01),\n",
        "                           bias_initializer=initializers.Constant(0.01))(state)\n",
        "    layer2 = layers.MaxPool2D(2, strides=2, padding=\"SAME\")(layer1)\n",
        "    layer3 = layers.Conv2D(filters=64, kernel_size=3, strides=2, activation=\"relu\", \n",
        "                           kernel_initializer=initializers.TruncatedNormal(mean=0., stddev=0.01),\n",
        "                           bias_initializer=initializers.Constant(0.01))(layer2)\n",
        "    layer4 = layers.Flatten()(layer3)\n",
        "    q_value = layers.Dense(units=2, activation=\"linear\", \n",
        "                           kernel_initializer=initializers.TruncatedNormal(mean=0., stddev=0.01),\n",
        "                           bias_initializer=initializers.Constant(0.01))(layer4)\n",
        "\n",
        "    return keras.Model(inputs=state, outputs=q_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzw9d77fpZVd"
      },
      "source": [
        "Plot the model summary to make sure that the network is the same as expected. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "e4I23VOipZVd",
        "outputId": "b2c35a79-a05b-44ba-9465-6bd8afcb45fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 80, 80, 4)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 19, 19, 32)        3232      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 10, 10, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 4, 4, 64)          18496     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 23,778\n",
            "Trainable params: 23,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = create_q_model()\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDA31XqUpZVd"
      },
      "source": [
        "### Deep Q-learning\n",
        "\n",
        "We're now ready to implement the Q-learning algorithm.\n",
        "There are some subtle details in the implementation that you need to sort out. First, recall that the update rule for Q learning is\n",
        "\n",
        "$$Q(s,a) \\leftarrow Q(s,a) + \\alpha (r(s,a) + \\gamma\\cdot \\max_{a'} Q(\\text{next}(s,a), a') - Q(s,a))$$\n",
        "\n",
        "where $\\gamma$ is the discount factor and $\\alpha$ can be viewed as the step size or learning rate for gradient ascent.\n",
        "\n",
        "We'll set these as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DFXM0DpipZVd"
      },
      "outputs": [],
      "source": [
        "gamma = 0.99            # decay rate of past observations\n",
        "step_size = 1e-4        # step size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-G2yNippZVd"
      },
      "source": [
        "### Estimation with experience replay\n",
        "\n",
        "At the beginning of training, we spend 10,000 steps taking random \n",
        "actions, as a means of observing the environment. \n",
        "\n",
        "We build a replay memory of length 10,000 steps, and every time we update the weights of the network, we sample a batch of size 32 and perform a Q-learning update on this batch.\n",
        "\n",
        "After we have collected 10,000 steps of new data, we discard \n",
        "the old data, and replace it with the new \"experiences.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YLIlmnWvpZVd"
      },
      "outputs": [],
      "source": [
        "observe = 10000            # timesteps to observe before training\n",
        "replay_memory = 10000      # number of previous transitions to remember\n",
        "batch_size = 32            # size of each batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rDiviM1pZVd"
      },
      "source": [
        "\n",
        "### 3.3 Justify the data collection\n",
        "\n",
        "Why does it make sense to maintain the replay memory of a fixed size \n",
        "instead of including all of the historical data?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRIxXxikpZVd"
      },
      "source": [
        "Answer:\n",
        "Including all of the historical data will result in a significant amount of memory usage as the training progresses. The historical data very long time ago might also have little influence on the current training scheme. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T6HOwDkpZVd"
      },
      "source": [
        "### Exploration vs exploitation\n",
        "\n",
        "When performing Q-learning, we face the tradeoff between exploration and \n",
        "exploitation.  To encourage exploration, a simple strategy is to take a random action at each step with certain probability.\n",
        "\n",
        "More precisely, for each time step $t$ and state $s_t$, with probability $\\epsilon$, the algorithm takes a random action (wing flap or do nothing), and with probability $1-\\epsilon$ the \n",
        "algorithm takes a greedy action according to $a_t = \\arg\\max_{a} Q_\\theta(s_t,a)$. Here $\\theta$ refers to the parameters of our CNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vto8Tv0OpZVd"
      },
      "outputs": [],
      "source": [
        "# value of epsilon\n",
        "epsilon = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnhcwTjopZVd"
      },
      "source": [
        "### 3.4 Complete the Q-learning algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i63WW4ONpZVd"
      },
      "source": [
        "Next you will need to complete the Q-learning algorithm by filling in the missing code in the following function.\n",
        "The missing parts include\n",
        "\n",
        "- Taking a greedy action\n",
        "- Given a batch of samples $\\{(s_t, a_t, r_t, s_{t+1}, \\text{terminal}_t)\\}_{t\\in B}$, computing the corresponding $Q_\\theta(s_t, a_t)$.\n",
        "- Given a batch of samples $\\{(s_t, a_t, r_t, s_{t+1}, \\text{terminal}_t)\\}_{t\\in B}$, computing the corresponding updated Q-values \n",
        "  \n",
        "$$\\hat{y}(s_t,a_t) = \\begin{cases}\n",
        "r_t + \\gamma\\, \\max_{a} Q_\\theta(s_{t+1}, a), & \\text{if } \\text{terminal}_t=0,\\\\\n",
        "r_t, & \\text{otherwise}.\n",
        "\\end{cases}$$\n",
        "\n",
        "Then, the mean squared error loss for the batch is\n",
        "\n",
        "$$\\frac{1}{|B|} \\sum_{t\\in B} (\\hat y(s_t, a_t) - Q_\\theta(s_t, a_t))^2.$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9rdYqtdFpZVe"
      },
      "outputs": [],
      "source": [
        "def dql_flappy_bird(model, optimizer, loss_function):\n",
        "\n",
        "    # initiate a game\n",
        "    game = flappy_bird.GameState()\n",
        "\n",
        "    # store the previous state, action and transitions\n",
        "    history_data = deque()\n",
        "\n",
        "    # get the first observation by doing nothing and preprocess the image\n",
        "    do_nothing = np.zeros(num_actions)\n",
        "    do_nothing[0] = 1\n",
        "    image, reward, terminal = game.frame_step(do_nothing)\n",
        "\n",
        "    # preprocess to get the state\n",
        "    current_state = preprocess(image_raw=image)\n",
        "    \n",
        "    # training\n",
        "    t = 0\n",
        "\n",
        "    while t < 50000:\n",
        "        if epsilon > np.random.rand(1)[0]:\n",
        "            # random action\n",
        "            action = np.random.choice(num_actions)\n",
        "        else:\n",
        "            # compute the Q function\n",
        "            current_state_tensor = tf.convert_to_tensor(current_state)\n",
        "            current_state_tensor = tf.expand_dims(current_state_tensor, 0)\n",
        "            q_value = model(current_state_tensor, training=False)\n",
        "            \n",
        "            # greedy action\n",
        "            #-----MISSING-----# \n",
        "            # your code here\n",
        "            action = np.argmax(q_value[0])\n",
        "            #-----------------#\n",
        "\n",
        "        # take the action and observe the reward and the next state\n",
        "        action_vec = np.zeros([num_actions])\n",
        "        action_vec[action] = 1\n",
        "        image_raw, reward, terminal = game.frame_step(action_vec)\n",
        "        next_state = preprocess(current_state=current_state, \n",
        "                                image_raw=image_raw)\n",
        "        \n",
        "        # store the observation\n",
        "        history_data.append((current_state, action, reward, next_state, \n",
        "                            terminal))\n",
        "        if len(history_data) > replay_memory:\n",
        "            history_data.popleft()  # discard old data\n",
        "\n",
        "        # train if done observing\n",
        "        if t > observe:\n",
        "\n",
        "            # sample a batch\n",
        "            batch = random.sample(history_data, batch_size)\n",
        "            state_sample = np.array([d[0] for d in batch]) # (32, 80, 80, 4)\n",
        "            action_sample = np.array([d[1] for d in batch]) # (32,)\n",
        "            reward_sample = np.array([d[2] for d in batch]) # (32,)\n",
        "            state_next_sample = np.array([d[3] for d in batch]) # (32, 80, 80, 4)\n",
        "            terminal_sample = np.array([d[4] for d in batch]) # (32,)\n",
        "\n",
        "            # compute the updated Q-values for the samples\n",
        "            #-----MISSING-----#\n",
        "            # your code here\n",
        "            # print(state_sample)\n",
        "            # print(state_sample.shape)\n",
        "            # print(action_sample.shape)\n",
        "            # print(reward_sample.shape)\n",
        "            # print(state_next_sample.shape)\n",
        "            # print(terminal_sample.shape)\n",
        "\n",
        "            updated_q_value_list = []\n",
        "            for i in range(batch_size):\n",
        "                if terminal_sample[i]:\n",
        "                    updated_q_value_list.append(reward_sample[i])\n",
        "                else:\n",
        "                    current_q_table = model(state_next_sample, training=False)\n",
        "                    updated_q_value_list.append(reward_sample[i] + gamma*np.max(current_q_table[i]))\n",
        "\n",
        "            updated_q_value = tf.convert_to_tensor(updated_q_value_list)\n",
        "            # print(updated_q_value)\n",
        "            #-----------------#\n",
        "\n",
        "            # train the model on the states and updated Q-values\n",
        "            with tf.GradientTape() as tape:\n",
        "                # compute the current Q-values for the samples\n",
        "                #-----MISSING-----#\n",
        "                # your code here\n",
        "                current_q_table = model(state_sample, training=False)\n",
        "                current_q_value = tf.convert_to_tensor([current_q_table[i, action_sample[i]] for i in range(batch_size)])\n",
        "                # print(current_q_value)\n",
        "                #-----------------#\n",
        "\n",
        "                # compute the loss\n",
        "                loss = loss_function(updated_q_value, current_q_value)\n",
        "\n",
        "            # backpropagation\n",
        "            grads = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "        else:\n",
        "            loss = 0\n",
        "\n",
        "        # update current state and counter\n",
        "        current_state = next_state\n",
        "        t += 1\n",
        "\n",
        "        # print info every 500 steps\n",
        "        if using_colab and t % 500 == 0: # previous every 3 steps\n",
        "            view = image_raw.transpose([1, 0, 2])\n",
        "            img_bgr = cv2. cvtColor(view, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "            display.clear_output(wait=True)\n",
        "            # output.clear(wait=True)\n",
        "            print(f\"STEP {t} | PHASE {'observe' if t<=observe else 'train'}\", \n",
        "                  f\"| ACTION {action} | REWARD {reward} | LOSS {loss}\")\n",
        "            plt.imshow(img_bgr)\n",
        "            display.display(plt.gcf())\n",
        "            # cv2_imshow(img_bgr)\n",
        "        elif t % 500 == 0:\n",
        "            print(f\"STEP {t} | PHASE {'observe' if t<=observe else 'train'}\", \n",
        "                  f\"| ACTION {action} | REWARD {reward} | LOSS {loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7isamyHpZVe"
      },
      "source": [
        "You're now ready to play the game! Just run the cell below; do not change the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "UFl8Ai_zpZVe"
      },
      "outputs": [],
      "source": [
        "def playgame(start_from_ckpt=False, ckpt_path=None):\n",
        "\n",
        "    #! DO NOT change the random seed !\n",
        "    np.random.seed(4)\n",
        "\n",
        "    if start_from_ckpt:\n",
        "        # if you want to start from a checkpoint\n",
        "        model = keras.models.load_model('ckpt_path')\n",
        "    else:\n",
        "        model = create_q_model()\n",
        "\n",
        "    # specify the optimizer and loss function\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=step_size, clipnorm=1.0)\n",
        "    loss_function = keras.losses.MeanSquaredError()\n",
        "\n",
        "    # play the game\n",
        "    dql_flappy_bird(model=model, optimizer=optimizer, loss_function=loss_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "skBbJm05pZVe",
        "outputId": "127680a8-d17a-4256-9f1e-9b6c00129308"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STEP 50000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.09207262098789215\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "playgame()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIttoAfUpZVe"
      },
      "source": [
        "### 3.5 Describe the training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r92oom7pZVe"
      },
      "source": [
        "Describe what you see by answering the following questions:\n",
        "\n",
        "- In the early stage of training (within 2,000 steps in the *explore* phase), \n",
        "  describe the behavior of the Flappy Bird. What do you think is the greedy policy \n",
        "  given by the estimation of the Q-function in this stage?\n",
        "- Describe what you see after roughly 5,000 training steps. \n",
        "  Do you see any improvement?\n",
        "  In particular, compare Flappy's behavior with their behavior in the early stages of \n",
        "  training.\n",
        "- Explain why the performance has improved, by relating to the model \n",
        "  design such as the replay memory and the exploration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kO57LxJOpZVe"
      },
      "source": [
        "Answer;\n",
        "- In the early stage of the training, the flappy bird crashes frequently. The greedy policy given by the estimation of the Q-function seems to be a random policy.\n",
        "- After roughly 5000 training steps, there are some improvement. The bird seems to be able to avoid some obstacles and the episode seems to be longer.\n",
        "- As in the early stage, the content in the replay buffer is mostly constructed in the observation stage. As the training progresses, the model is able to exploit and explore following the epsilon-greedy policy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqwmbSW8pZVe"
      },
      "source": [
        "It takes a long time to fully train the network, so you're not required to \n",
        "complete the training. Here's a [video](https://www.youtube.com/watch?v=THhUXIhjkCM) showing the performance of a well trained DQN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCMCNOH4pZVe"
      },
      "source": [
        "## Problem 4: Julius Tensor (15 points)\n",
        "\n",
        "In this problem you will modify a basic vanilla \"np-complete\" implementation of recurrent neural networks, and evaluate some pre-trained RNNs trained on the plays of \n",
        "William Shakespeare.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HXRt5uJGpZVe"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import logging\n",
        "tf.get_logger().setLevel(logging.ERROR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QuG-kHiqpZVe"
      },
      "outputs": [],
      "source": [
        "def generate_shakespeare(model, size=1000, seed='ROMEO:'):\n",
        "    states = None\n",
        "    next_char = tf.constant([seed])\n",
        "    result = [next_char]\n",
        "                             \n",
        "    for n in range(1000):\n",
        "      next_char, states = model.generate_one_step(next_char, states=states)\n",
        "      result.append(next_char)\n",
        "\n",
        "    return tf.strings.join(result)[0].numpy().decode(\"utf-8\")\n",
        "                             "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzP54nYopZVe"
      },
      "source": [
        "### Problem 4.1: Word play\n",
        "\n",
        "We have upload three pre-trained models for you to experiment with: 'Hamlet', 'Macbeth', and 'Comedy of Errors'. One of the models has 256 hidden neurons in the GRU layer, and was trained\n",
        "for 30 epochs. The two other models each have have 1024 hidden neurons in the GRU layer; one was trained for 30 epochs, and the other trained for 50 epochs. \n",
        "\n",
        "Generate sample text from each, using the function `generate_shakespeare` defined above, in order to evaluate the models. Which model is which? Explain how you made your assessment.\n",
        "\n",
        "You can download the models 'Hamlet', 'Comedy_of_Errors' and 'Macbeth' from \n",
        "https://github.com/YData123/sds365-sp22/tree/main/assignments/assn4.\n",
        "\n",
        "Note: If you are unable to load and run these models on your own computer, please run \n",
        "them in the cloud on Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTNb3ACYpZVe"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "def func_unzip(path_to_zip_file, directory_to_extract_to):\n",
        "    with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
        "        zip_ref.extractall(directory_to_extract_to)\n",
        "\n",
        "func_unzip('Hamlet.zip','Hamlet_unzip')\n",
        "func_unzip('Comedy_of_Errors.zip','Comedy_of_Errors_unzip')\n",
        "func_unzip('Macbeth.zip','Macbeth_unzip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UONzN7FnpZVe"
      },
      "outputs": [],
      "source": [
        "pretrained1 = tf.saved_model.load('./Hamlet_unzip/Hamlet')\n",
        "pretrained2 = tf.saved_model.load('./Comedy_of_Errors_unzip/Comedy_of_Errors')\n",
        "pretrained3 = tf.saved_model.load('./Macbeth_unzip/Macbeth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "V0NhFectpZVf",
        "outputId": "dbd7dff3-0a2d-4ecd-8e6f-4fe7c4fbc6a5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"ROMEO:\\nThe news I have my cousin, she you make\\nnone. Lay her father, boy; the more\\nShall bear their very watch your face to weep:\\nBut passing with a double och an appreheth ear\\nWas much, but consumed with his brazen jace.\\n\\nRICHARD:\\nAre it confirmn your highness' mouth:\\nTherefore I came unto myself: if it be\\nnone affended, how it lies your life, for if\\nhe seeming him, which never be sportful:\\nWas gratifuely entering me?\\n\\nLUCIO:\\n'Tis but the last,\\nStand by a puppet of me. Tybalt thanks, nay, my\\ntood bide an enemy, faintly speak,\\nNor I lest choose him for my either corpedet\\nTo have you assist them. Now to London citizens\\nHath the stone raised with armies in arms.\\n\\nANTONIO:\\nThat so strays the strength of murderers.\\n\\nANGELO:\\nBelieve me, sir?\\n\\nPROSPERO:\\nFor what, provide!\\n\\nKATHARINA:\\nI will be satisfied.\\n\\nPAULINA:\\nTraitors!\\nGo thou to Friar Lador, Sirrah!\\n\\nTRANIO:\\nIn this same very pretty one hath life\\nA kinsman nature? were there you assign, not in me\\nTo bring this tide and England's queen.\\nAnd y\""
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Your code and markdown here \n",
        "generate_shakespeare(pretrained1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "EvgXe706rlZQ",
        "outputId": "e03f09c4-53e7-48db-b448-714de95b0288"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"ROMEO:\\nTell me that you shall call me that hear\\nThe time hath wit or pains within my foxted. If Irelo!\\n\\nKING RICHARD III:\\nFaithiest merry of this open wits,\\nAnd Menening thou envy stand, ere I this angel\\nDake miseray'd by Parter that should keep me deed,\\nYond faged, and all the glorious stately: have you may find\\nFirst Romeo: but I will his courtesy.\\n\\nHASTINGS:\\nYe'? after sweet in this resive.\\nFly, Rickond, and strange youth--\\n\\nGroe I'll give as he had; for any heavine\\nThe world was he o' the owa, frowns more may hath wife,\\nThat makes the one harve thee for his queen, I\\ndaught the flournewing of her.\\n\\nDUKE OF YORK:\\nSent for a foultiers for that made the city;\\nFeveren. O my what they give it o'erf:\\nAppeak thy trull joys were royal fool\\nThat wondrous rank earsh of deature\\nThan more than you are their land.\\n\\nEDWARD:\\nThe napkerech you, Henry purges on my heart:\\nThere lies: dishonour; you but that your heads;\\nAnd have the bastard Elikent on only son:\\nOur sheeps in your house: behold put in this m\""
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_shakespeare(pretrained2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "zRGZ1w8nrpAD",
        "outputId": "60dbc726-c351-4700-9926-42e7065b6985"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"ROMEO:\\nI do beseech you, I mean now; the forten years\\n'done Tybrazia, for I have been a\\ncounterfeitful virgin: keep with you; who,\\nthey have a king King Richard and matter.\\n\\nJULIET:\\nThat ill beseech you, who is this ang again?\\nNow fair an irrooation bears me up,\\nAnd long to when I saw in these nobles were\\nFrom your isconsidence and unfold.\\n\\nDUKE OF YORK:\\nIf that have done this true affacious in the city,\\nFlier fettle issue of this world.\\n\\nThird York:\\nHave affected my heart my writ. Piop, my business in rebellike\\nA king of end, but forrow I give love,\\nGo thwire angers, for I thank\\nthee, noble Welshmely gazed me: thou\\nart a shamp-well corn, obey eyes: believe thee want, if\\nyou will follow thee. Come, you are happy,\\nAnd do not break our common wealth, as she art\\nWith down, her hors' excalled o' the rest,\\nAnd fly to demosit them all.\\n\\nLUCIO:\\nCall doth my lesson?\\n\\nANTONIO:\\nWent them to Aufidius,\\nDo not be were dishonour'd to bedward;\\nYou must return again in France.\\n\\nHASTINGS:\\nAs thou didst prove\""
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_shakespeare(pretrained3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Answer: \n",
        "The first pretrained model might be the one with 1024 hidden neurons trained with 50 epochs. I feel like the punctuation is more consistent than the other two and the grammar is better. The second pretrained model might be the one with 256 hidden neurons trained 30 epochs given the worst grammar and quite inconsistent sentences. The last pretrained model might te one with 1024 hidden neurons trained with 30 epochs as it seems a little bit worse than the first generated model. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wgks8sL_pZVf"
      },
      "source": [
        "### Problem 4.2: np-complete implementation of RNNs\n",
        "\n",
        "Run the [basic rnn code](https://github.com/YData123/sds365-sp22/blob/main/assignments/assn4/shakespeare_rnn.py) from [Andrej Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) to train a model on the [Shakespeare data](https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt). \n",
        "Modify the code however you see fit, for example, by changing how often a snippet of synthetic text is generated.\n",
        "\n",
        "* How many steps of gradient descent did you train for? How many characters of Shakespeare data was processed during training? How long did the training take?\n",
        "\n",
        "* Did you modify the code in any way? If so, how?\n",
        "\n",
        "* Provide a few examples of generated text from your trained model.\n",
        "\n",
        "* How do the generated samples compare to those generated\n",
        "in Problem 4.1?\n",
        "\n",
        "* Describe at least three differences between this vanilla RNN model\n",
        "and the GRU networks that you experimented with in 4.1, which are described [here](https://www.tensorflow.org/text/tutorials/text_generation).\n",
        "\n",
        "Note: To limit the output the graders need to examine, please experiment in a separate Python session, and only include your final results in this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code and markdown here \n",
        "!python shakespeare_rnn.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Answer:\n",
        "- I performed 30000 steps of gradient descent. There are 1115394 characters of Shakespeare data that were processed in the training. The training took about 4 minutes and 30 seconds.\n",
        "- I didn't modify the code.\n",
        "- Here are few examples \n",
        "    -   ivey ofr whranes, hew,\n",
        "        Hossaimess;\n",
        "        And what od brote?\n",
        "        Thit prond.\n",
        "        GORSI ERCAGR, IN HI:\n",
        "        O ark!\n",
        "        Thy noal Dewill as rovet stay rid I pisenuch my my fzote thy staus him cameil mo frepars\n",
        "        I ware badyorwe\n",
        "    -   UKES:\n",
        "        The ckamirk IDcionce:\n",
        "        Teen't awispfe'd mr hotht aw.\n",
        "        Lhather monive lood is ay mae be cextom!\n",
        "        The ADand orlat nously do sionh\n",
        "        Utht a I, a gricaniegers cobyol grossins toover rened so mu'd ore, y \n",
        "- The generated text is worse than those generated in problem 4.1 as most words are incorrect.\n",
        "- Here are the differences:\n",
        "    - The number of hidden neurons is larger in 4.1 model and thus its generative capacity is larger.\n",
        "    - The model in 4.1 involves a trainable embedding layer to extract the features of the raw text.\n",
        "    - The GRU model in 4.1 addresses the vanishing gradient issue in the vanilla RNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3knc1LppZVf"
      },
      "source": [
        "### Problem 4.3: Adding a layer \n",
        "\n",
        "Now suppose you wish to add another recurrent hidden layer to the np-complete RNN implementation. Rather than implementing the full model training, \n",
        "we'd like you to implement the generator. (But we encourage you to at least partially implement the full training of the two-layer model.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Xp0OHQkpZVf"
      },
      "source": [
        "Here is the generator for the model that has a single recurrent layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWtRpvv6pZVf"
      },
      "outputs": [],
      "source": [
        "def sample(h, seed_ix, n):\n",
        "    \"\"\"\n",
        "    sample a sequence of integers from the model\n",
        "    h is memory state, seed_ix is a seed letter for first time step\n",
        "    \"\"\"\n",
        "    x = np.zeros((vocab_size, 1))\n",
        "    x[seed_ix] = 1\n",
        "    ixes = []\n",
        "    for t in range(n):\n",
        "        h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
        "        y = np.dot(Why, h) + by\n",
        "        p = np.exp(y) / np.sum(np.exp(y))\n",
        "        ix = np.random.choice(range(vocab_size), p=p.ravel())\n",
        "        x = np.zeros((vocab_size, 1))\n",
        "        x[ix] = 1\n",
        "        ixes.append(ix)\n",
        "        \n",
        "    return ixes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M_Fp1wXpZVf"
      },
      "source": [
        "Your job is to rewrite this function for a model that has two hidden recurrent layers.\n",
        "Complete the implementation below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0Bxyjx4pZVf"
      },
      "outputs": [],
      "source": [
        "def sample2(h1, h2, seed_ix, n):\n",
        "    \"\"\"\n",
        "    sample a sequence of integers from the model\n",
        "    h1, h2 is memory state, seed_ix is a seed letter for first time step\n",
        "    \"\"\"\n",
        "    x = np.zeros((vocab_size, 1))\n",
        "    x[seed_ix] = 1\n",
        "    ixes = []\n",
        "    for t in range(n):\n",
        "        h1 = np.tanh(np.dot(Wxh1, x) + np.dot(Whh1, h1) + bh1)\n",
        "        h2 = np.tanh(np.dot(Wh1h2, h1) + np.dot(Whh2, h2) + bh2)\n",
        "        y = np.dot(Why, h2) + by\n",
        "        p = np.exp(y) / np.sum(np.exp(y))\n",
        "        ix = np.random.choice(range(vocab_size), p=p.ravel())\n",
        "        x = np.zeros((vocab_size, 1))\n",
        "        x[ix] = 1\n",
        "        ixes.append(ix)\n",
        "\n",
        "    return ixes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w31q14yBpZVf"
      },
      "source": [
        "Explain your implementation, by giving a description of each line of the code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnrrACNfpZVf"
      },
      "source": [
        "Answer:\n",
        "Only the first three lines are different from the previous example. \n",
        "1. By adding another hidden layer, we first compute the updated state h1 from the current input (Wxh1), previous memory (Whh1) and the bias term.\n",
        "2. We then compute the updated second hidden state from the previous hidden state input (Wh1h2), previous memory (Whh2) and the bias term.\n",
        "3. We finally compute the output value using the second hidden state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gZg9cH9pZVf"
      },
      "source": [
        "### Problem 4.4 Be the Bard (optional, 2 points EC)\n",
        "\n",
        "Starting from the [TensorFlow tutorial](https://www.tensorflow.org/text/tutorials/text_generation), train the best model \n",
        "that you can, generating synthetic Shakespeare that is better than the best model\n",
        "from problem 4.1 above. \n",
        "\n",
        "* Describe how the model is indeed better than the best model in 4.1.\n",
        "* Provide details on how you trained the model, and any changes made to the model \n",
        "architecture.\n",
        "* So that you do not add too much stuff to your notebook, put your code in a separate notebook (submitted to Canvas), and only add Markdown below to detail your results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lzQRN8MpZVf"
      },
      "source": [
        "Answer:\n",
        "- The model seems to be more capable than the model in 4.1 The generated text seems to be more consistent and the punctuation seems to be more reasonable.\n",
        "- The model contains an embedding layer, a single GRU layer with 2048 units followed by a fully connected layer. We utilize the Adam optimizer with sparse categorical cross entropy loss on the model.\n",
        "- The code used in this problem is titled as \"p4.ipynb\" and submitted in canvas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Copy of assn4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
