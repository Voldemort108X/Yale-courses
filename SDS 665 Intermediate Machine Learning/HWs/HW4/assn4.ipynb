{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermediate Machine Learning: Assignment 4\n",
    "\n",
    "**Deadline**\n",
    "\n",
    "Assignment 4 is due Wednesday, April 27 by 11:59pm. Late work will not be accepted as per the course policies (see the Syllabus and Course policies on Canvas).\n",
    "\n",
    "Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged.\n",
    "\n",
    "You should start early so that you have time to get help if you're stuck. The drop-in office hours schedule can be found on Canvas. You can also post questions or start discussions on Ed Discussion. The assignment may look long at first glance, but the problems are broken up into steps that should help you to make steady progress.\n",
    "\n",
    "**Submission**\n",
    "\n",
    "Submit your assignment as a pdf file on Gradescope, and as a notebook (.ipynb) on Canvas. You can access Gradescope through Canvas on the left-side of the class home page. The problems in each homework assignment are numbered. Note: When submitting on Gradescope, please select the correct pages of your pdf that correspond to each problem. This will allow graders to more easily find your complete solution to each problem.\n",
    "\n",
    "To produce the .pdf, please do the following in order to preserve the cell structure of the notebook:\n",
    "\n",
    "Go to \"File\" at the top-left of your Jupyter Notebook\n",
    "Under \"Download as\", select \"HTML (.html)\"\n",
    "After the .html has downloaded, open it and then select \"File\" and \"Print\" (note you will not actually be printing)\n",
    "From the print window, select the option to save as a .pdf\n",
    "\n",
    "**Topics**\n",
    "\n",
    " * Graph kernels\n",
    " * Reinforcement learning\n",
    " * Recurrent neural networks\n",
    "\n",
    "This assignment will also help to solidify your Python skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\renewcommand{\\reals}{{\\mathbb R}}\n",
    "\\newcommand{\\indp}{\\perp\\kern-4pt\\perp}\n",
    "\\newcommand{\\given}{\\,|\\,}\n",
    "$\n",
    "\n",
    "## Problem 1: Graph kernels (10 points)\n",
    "\n",
    "The graph Laplacian for a weighted graph on $n$ nodes is defined as\n",
    "\n",
    "$$ L = D - W$$\n",
    "\n",
    "where $W$ is an $n\\times n$ symmetric matrix of positive edge weights,\n",
    "with $W_{ij} = 0$ if $(i,j)$ is not an edge in the graph,\n",
    "and $D$ is the diagonal matrix with $D_{ii} = \\sum_{j=1}^n W_{ij}$.\n",
    "This generalizes the definition of the Laplacian\n",
    "used in class, where all of the edge weights are one.\n",
    "\n",
    "\n",
    "1. Show that $L$ is a Mercer kernel, by showing that $L$ is\n",
    "  symmetric and positive-semidefinite.\n",
    "<br>\n",
    "\n",
    "Answer:\n",
    "We first show that $L$ is a symmetric matrix. As we have\n",
    "\\begin{align}\n",
    "  L &= D - W \\\\\n",
    "    &= D^T - W^T \\\\\n",
    "    &= L^T.\n",
    "\\end{align}\n",
    "For any vector $x=[x_1,...,x_n]^T$, we have\n",
    "\\begin{align}\n",
    "  x^TLx &= \\sum_{i=1}^n\\left(x_i^2\\sum_{j=1}^nW_{ij}-x_i\\sum_{j=1}^nx_jW_{j1} \\right) \\\\\n",
    "        &= \\sum_{i\\neq j}(x_i-x_j)^2W_{ij} \\\\\n",
    "        &\\geq 0 \n",
    "\\end{align}\n",
    "given $W_{ij}\\geq 0$. Thus $L$ is a symmetric and positive-semidefinite matrix, which shows that $L$ is a Mercer kernel.\n",
    "\n",
    "2. In graph neural networks we define polynomial filters of the form\n",
    "\n",
    "  $$ P = a_0 I + a_1 L + a_2 L^2 + \\cdots a_d L^d$$\n",
    "  \n",
    "  where $L$ is the Laplacian and $a_0,\\ldots, a_d$ are parameters,\n",
    "  corresponding to the filter parameters in standard convolutional\n",
    "  neural networks.\n",
    "\n",
    "  If each $a_i \\geq 0$ is non-negative, show that $P$ is also\n",
    "  a Mercer kernel. \n",
    "<br>\n",
    "\n",
    "Answer: \n",
    "For each term in the polynomial, we have\n",
    "\\begin{align}\n",
    "  x^Ta_iL^ix = \n",
    "  \\begin{cases}\n",
    "    a_i(xL^k)^TLxL^k\\geq 0 & i=2k+1 \\\\\n",
    "    a_i\\|xL^k\\|^2\\geq 0 & i=2k\n",
    "  \\end{cases}\n",
    "\\end{align}\n",
    "for any $x\\in\\mathbb{R}^n$. As each term in $P$ is symmetric as shown in (1), $P$ is a symmetric and positive semi-definite matrix, which is also a Mercer kernel.\n",
    "\n",
    "3. Is positivity of the coefficients $a_i$ a necessary condition? Explain.\n",
    "\n",
    "Answer: \n",
    "The positivity of the coefficients is not a necessary condition as we only need the sum of the quadratic term to be greater than zero for any $x$. The positivity of the coefficients $a_i$ is a sufficient condition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##  Problem 2:  Positive reinforcement  (10 points)\n",
    "<!-- $\\def\\J{{\\mathcal J}}$\n",
    "$\\def\\E{{\\mathbb E}}$ -->\n",
    "\n",
    "As discussed in class, reinforcement learning\n",
    "using policy gradient methods is based on maximizing the\n",
    "expected total reward\n",
    "\n",
    "$$ \\mathcal{J}(\\theta) = \\mathbb{E}_\\theta [R(\\tau)],$$\n",
    "\n",
    "where the expectation is over the probability distribution over sequences $\\tau$ through a choice of actions using the policy. This can be rewritten as\n",
    "\n",
    "\\begin{align*}\n",
    "  \\nabla_\\theta \\mathcal{J}(\\theta) & = \\mathbb{E}_\\theta\\left[ R(\\tau) \\nabla_\\theta \\log p(\\tau\\,|\\, \\theta) \\right].\n",
    "\\end{align*}\n",
    "\n",
    "Approximating this gradient involves computing $\\nabla_\\theta \\log \\pi_\\theta (a\\,|\\, s)$ where $\\pi_\\theta$ is the policy.\n",
    "\n",
    "Suppose that the action space is continuous\n",
    "and $\\pi_\\theta(a\\,|\\, s)$ is a normal density with mean\n",
    "$\\mu_\\theta(s)$ and variance $\\sigma^2_\\theta(s)$, two outputs of\n",
    "a neural network with input $s$ and parameters $\\theta$.\n",
    "\n",
    "1. Suppose the outputs of the neural network are given by\n",
    "\n",
    "\\begin{align*}\n",
    "  \\mu_\\theta(s) & = \\beta_1^T h(s) \\\\\n",
    "  \\sigma^2_\\theta(s) &= \\text{sigmoid}(\\beta_2^T h(s))\n",
    "\\end{align*}\n",
    "\n",
    "where $h(s)$ is the vector of neurons in the last layer, immediately\n",
    "before the outputs. Derive explicit expressions for\n",
    "$\\nabla_{\\beta_1} \\log \\pi_\\theta(a\\,|\\, s)$ and\n",
    "$\\nabla_{\\beta_2} \\log \\pi_\\theta(a\\,|\\, s)$.\n",
    "\n",
    "Answer:\n",
    "To compute the gradients, we first have\n",
    "\\begin{align}\n",
    "  \\log\\pi_\\theta(a|s) &= \\log\\frac{1}{\\sqrt{2\\pi}\\sigma(s)}e^{-\\frac{(a-\\mu(s))^2}{2\\sigma^2(s)}} \\\\\n",
    "                      &= -\\log\\sqrt{2\\pi}\\sigma(s) - \\frac{(a-\\mu(s))^2}{2\\sigma^2(s)}\n",
    "\\end{align}\n",
    "\n",
    "and then we have\n",
    "\\begin{align}\n",
    "  \\nabla_{\\beta_1}\\log\\pi_\\theta(a|s) &= -\\frac{\\mu(s)-a}{\\sigma^2(s)}\\nabla_{\\beta_1}\\mu(s) \\\\\n",
    "                                      &= -\\frac{\\mu(s)-a}{\\sigma^2(s)}h(s) \\\\\n",
    "                                      &= -\\frac{\\beta_1^T h(s)-a}{\\text{sigmoid}(\\beta_2^T h(s))}h(s)\n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "  \\nabla_{\\beta_2}\\log\\pi_\\theta(a|s) &= \\left(-\\frac{1}{\\sigma(s)} + \\frac{(a-\\mu(s))^2}{\\sigma(s)^3} \\right)\\nabla_{\\beta_2}\\sigma(s) \\\\\n",
    "                                      &= \\left(-\\frac{1}{\\sigma(s)} + \\frac{(a-\\mu(s))^2}{\\sigma(s)^3} \\right)\\sigma^2(s)h(s) \\\\\n",
    "                                      &= \\left(-\\text{sigmoid}(\\beta_2^T h(s)) + \\frac{(a-\\beta_1^T h(s))^2}{\\text{sigmoid}(\\beta_2^T h(s))} \\right)h(s)\n",
    "\\end{align}\n",
    "<br>\n",
    "\n",
    "2. Explain how these gradients and other gradient\n",
    "terms in $\\nabla_\\theta \\log \\pi_\\theta(a\\,|\\, s)$ are used\n",
    "to estimate the policy.\n",
    "\n",
    "Answer:\n",
    "We parameterize the policy as $\\pi_\\theta(a|s)$ and use the gradient ascent on the loss function to estimate the policy. As we can use the total expected reward as the loss, we have\n",
    "\\begin{align}\n",
    "  \\mathcal{L}(\\theta) &= \\mathbb{E}_\\theta(R(\\tau)) \\\\\n",
    "                      &= \\int p(\\tau|\\theta)R(\\tau)d\\tau.\n",
    "\\end{align}\n",
    "From the lecture slides, we can approximate the gradient by\n",
    "\\begin{align}\n",
    "  \\nabla_\\theta\\mathcal{L}(\\theta) &\\approx \\frac{1}{N}\\sum_{i=1}^NR(\\tau^{(i)})\\nabla_\\theta\\log p(\\tau^{(i)}|\\theta) \\\\\n",
    "                                   &= \\frac{1}{N}\\sum_{i=1}^NR(\\tau^{(i)})\\sum_{t=0}^T\\nabla_\\theta\\log\\pi_\\theta(a_t^{(i)}|s_t^{(i)}).\n",
    "\\end{align}\n",
    "The parameters of policy gradient are then updated iteratively by \n",
    "\\begin{align}\n",
    "  \\theta \\leftarrow \\theta + \\eta\\hat{\\nabla_\\theta\\mathcal{L}(\\theta)}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Deep Q-Learning for Flappy Bird (25 points)\n",
    "\n",
    "Deep Q-learning was proposed (and patented) by DeepMind and made \n",
    "a big splash when the same deep neural network architecture was shown to be able to surpass\n",
    "human performance on many different Atari games, playing directly from the pixels.\n",
    "In this problem, we will walk you through the implementation of deep Q-learning \n",
    "to learn to play the Flappy Bird game.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/YData123/sds365-sp22/main/assignments/assn4/images/flappy_bird_demp.gif\" width=\"144\" height=\"256\"/>\n",
    "\n",
    "The implementation is based these references:\n",
    "- [DeepLearningFlappyBird](https://github.com/yenchenlin/DeepLearningFlappyBird)\n",
    "- [Deep Q-Learning for Atari Breakout](https://keras.io/examples/rl/deep_q_network_breakout/)\n",
    "\n",
    "We use the `pygame` package to visualize the interaction between the algorithm \n",
    "and the game environment. \n",
    "However, _pygame_ is not well supported by Google Colab; \n",
    "we recommend you to run the code for this problem locally.\n",
    "A window will be popped up that displays\n",
    "the game as it progress in real-time (as for the Cartpole demo from class).\n",
    "\n",
    "This problem is structured as follows:\n",
    "\n",
    "* Load necessary packages\n",
    "* Test the visualization of the game, to make sure everything's working\n",
    "* Process the images to reduce the dimension\n",
    "* Setup the game history buffer \n",
    "* Implement the core Q-learning function\n",
    "* Run the learning algorithm\n",
    "* Interpret the results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please make sure that the following files are in the same place:\n",
    "- assn4.ipynb\n",
    "- wrapped_flappy_bird.py\n",
    "- flappy_bird.utils.py\n",
    "- assets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do use Google Colab, set `using_colab` to be *True* in the following cell.\n",
    "If you access extra files through Google Drive, then uncomment the `'%cd ...'` \n",
    "line and change `PATH` to where you store the files on your Google Drive (need not to do this if you are using the temporary files for Colab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# from google.colab.patches import cv2_imshow\n",
    "# from google.colab import output\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "using_colab = True\n",
    "\n",
    "if using_colab:\n",
    "    os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "    # %cd /content/drive/MyDrive/PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Flappy Bird game requires a few Python packages. Please install these _as soon as possible_, and notify us of any issues you experience so that we can help. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygame in /home/xiaoranzhang/anaconda3/envs/tf2_env/lib/python3.6/site-packages (2.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: opencv-python in /home/xiaoranzhang/anaconda3/envs/tf2_env/lib/python3.6/site-packages (4.5.5.64)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/xiaoranzhang/anaconda3/envs/tf2_env/lib/python3.6/site-packages (from opencv-python) (1.18.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "pygame 2.1.2 (SDL 2.0.16, Python 3.6.13)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "%pip install pygame\n",
    "%pip install opencv-python\n",
    "import numpy as np\n",
    "import cv2\n",
    "import wrapped_flappy_bird as flappy_bird\n",
    "from collections import deque\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, initializers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Flappy Bird environment \n",
    "\n",
    "Interaction with the game environment is carried out through calls of the form\n",
    "\n",
    "`(image, reward, terminal) = game.frame_step(action)`\n",
    "\n",
    "where the meaning of these variables is as follows:\n",
    "\n",
    "- `action`: $\\binom{1}{0}$ for doing nothing, $\\binom{0}{1}$ for \"flapping the bird's wings\"\n",
    "- `image`: the image for the next step of the game, of size $(288, 512, 3)$ with three RGB channels\n",
    "- `reward`: the reward received for taking the action; -1 if an obstacle is hit, 0.1 otherwise. \n",
    "- `terminal`: `True` if an obstacle is hit, otherwise `False`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at the game interface.\n",
    "First, initiate the game:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of image: (288, 512, 3)\n",
      "reward:  0.1\n",
      "terminal:  False\n"
     ]
    }
   ],
   "source": [
    "num_actions = 2\n",
    "\n",
    "# initiate a game\n",
    "game = flappy_bird.GameState()\n",
    "\n",
    "# get the first state by doing nothing\n",
    "do_nothing = np.zeros(num_actions)\n",
    "do_nothing[0] = 1\n",
    "image, reward, terminal = game.frame_step(do_nothing)\n",
    "\n",
    "print('shape of image:', image.shape)\n",
    "print('reward: ', reward)\n",
    "print('terminal: ', terminal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After (locally) running the above cells, a window should pop up, and you can watch the game being played in that window. \n",
    "\n",
    "Let's take some random actions and see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAAD8CAYAAAD0dn+cAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAZzUlEQVR4nO2de5Ac13WfvzPPnX0ACyyAxYIgRUqkHvSDEkUrZIlxEtmyKdplKY5jS5VYKodV/CdO5ErFMeSkoriSqlhWynZUdrlMx0rklCNGsSWLVslhaJlKFJcFkYxoEqQEviSSIB4LAvveeXaf/NGP6W7MYBfA7vad3vNVNfr2vY2ZMzO/PffZ94iqYhh5U8rbAMMAE6LhCCZEwwlMiIYTmBANJzAhGk6wLUIUkXtE5KSIvCAix7bjPYxiIVs9jigiZeA54L3AKeAx4EOq+uyWvpFRKLbDI74LeEFVX1LVDvAg8P5teB+jQFS24TWvA15NXJ8C/sbl/oOI7Oj0TklKVOsTVKuN4Fp71KoVWp0Wa2srKNtrTrVSo7pngl49YVOpRKlcplQuUy6XKZcrlMsVSuVKkF8qAYrv+fi+h9fr4Xk9PM9DLzZZW1zAV39b7b5WKuUq3V5HBpbttDERInI/cP9OvmepVObI0ds4fOtPMj/1t7gw8QMclqe4701P8U/+6c/w5BMn+Nf/6t/wl8e/SqfX3jY7Dkwf5rp73sXFm8PfRIT6WIPxiT1M7p1mano/e/bNsGd6hqk9+xjfs5dGYwLf92mur7C2vMTK4kWWFy+wsniRzmdP8Fd/+nnWmivbZvO1IlKiXmsMLd8OIb4GXJ+4PhrmpVDVB4AHYGc8okiJ647eRu2dH+dE/V66C4L/qsdNkw/x9z7+j6jVaxycPcDP/sMPA/B/jz9Kt9fZbrMyRoYnBaIjuoZ+RnzvQOcykmxHG/Ex4BYRuUlEasAHgYe24X2uiDcc+T68I7/CK817aH0XvKXgR/VRLrSWUJRvPX2SqakJ7rzj3dSqYztnnA671IzWJHPvdjcido4t94iq2hORnwceBsrAp1X1ma1+nyuhJCWOzh6B2uPcuP4k1OAV7wd5zbuTp5of5MHf+wv2/7Np3vED34+q8vjxJ8M2WT5INhFnJCSqmaIRZ1vaiKr6ZeDL2/HaV8Nbbvx+Pv7vf4lbbnkjAL4qD372Uf7Dl6a44H0Pf/SNNc4e+z3q5eBnvXhhgVtv+2Ge/ubDrOfQ7lIBkTCRRQC0MAKMyK2zspN4vsfLF04ze/gg5VKZlc4651eWUb/LVPk73HD0G7zyrg+gSS/YWuOmpXmefeZrO1MBZpp/qlEiU5gypThy3BVCfO7lE3zyl3+VI7NvY5G3oCqc7n0vC94Ybx5/BHnTG6g99TXwo1/Zh5NP8M3nju9cKyyhKdXY8WUKs+eitBB3iRBBef7lE7R6NcqH7mJZj/K6/xYAXlh/N/7/foLZu+aQUvADq+8xf/Ehel5vJ00M5aWJf0m4R9L5cWEx2CVCBF99Tp1+koPNs0xOvZXDB+6Oy7zlJV76z18A9YDgd3998Sy+7+2cgXGHOCkuDTMleVtUgvWaRxTP73H2wilqS+dpvP7/4nzf91hZX8rRsjQyrCZO3rNTxuwQu0qIEZ1em87q9s2cbAnRgPVAxSnDKutRxdYjOogSza4o2QHsos2oRJgQXeKSQeqs4BIll4x6jzYmRJcINaXJPkp6HKefDG8ohgxNiA6R9oODxxEj+mosRgvRhOgQ6amVoQJL9aTNIxrbSDyzAqnlYPF1rNSi+EMTolNIqLp+PyS7DCx1MwBF2bvIhOgQGrYOYycYrb4ZWv9Ksvs80pgQnUFSyeRwYX/2OdVlLhQmRGdID9HETcC4do770onbiyNIE6KDSFTjZrTXF54MWCAx2pgQXSCjp/7MXii85HhiRphFkaIJ0QUG1bCZ5V/ZeyXVfhx9TIgukl2APehpW816y9HGhOg6gzxjQcYOk5gQXSEzOhMP3wzqrEhxxg8jTIiukBBd3GPejOfb2W2Dtg0TooPE+ot7JIPaiDtmzo5gQnQRyWjvkodYkiOKxaiiTYguE7YbL3V+/cUQRXGMJkSHSPo2iVbGDnx+SuK5laJgQnSI5Pwy0ZYj/ZJ0xaxBj6YYFbMJ0T3CkZmUKEM0dVM2b7TZlc81u4fiex69bod2a521leBn8Xo92q0mqyuL1OoNVH3azSbN9VWaq8usrS7TXFuh5O3gjhTbhAlxh6lV6uybOkB9GfacSvqzFtCixQVawMUreM29iz4Hp+dottac30d7GCbEHaYxNsHBm29idRrKW7Qz8uqREtevv5nXzn8Xf6e3W94iTIg50JmEhTf2uxmlcplKpUq1VqNaq1OtjVGrj1EbG6NWb1CvB9fVWp1qfYxKtUqlUkVE8Ho9uq02p/7tn+T3gbYAE6IDSKlEuVKhWq1THxtnbHyCxvgkYxNTNCYmaYxP0hifYKwxQX18nHq9QbVWR0pCt9OhvbrG2Wp94zdymA17zSLyaRGZF5ETibz9IvKIiDwfnveF+SIinwpDnz0lIrdvp/FFYeAqLwasw872lDd8uModxmqNy5q5meGb/wLck8k7BnxFVW8BvhJeA7wPuCU87gd+54qs3aVEQzWpWT2C9dcDB64HbO7uOm+98TaoDpfbhkJU1f/DpZ249wOfCdOfAT6QyP8DDfg6MC0ic1dq9K5EpL9ldpTFAKklp/1GwBNGSKlErzHc4Ksd0J5V1TNh+iwwG6YHhT+7bqBhIveLyOMi8vhV2lAsBs4pDxZjeplidiuI0eSaOyuqqlcTOWqnI0+5jIiEMypCSSS8DmdPpBQmBzzWN3STptHjaoV4TkTmVPVMWPXOh/mbCn+22ylpibpfpVKtU6vXqdcb1BsN6o0JxhpBr3msEfaSG+PUxxpBz7oLZfFRr0truUWv26HTbtNeW8Xv7eDG89vA1QrxIeAjwK+G5y8m8n9eRB4kiEi6lKjCDYKYL953FtjzarhgQQRFaAm0RVgWQeh7xeieCEk8vqcoaLA1XXt5ZbT3wVHVyx7AZ4EzQJegzXcfMEPQW34e+HNgf3ivAL8NvAg8Ddyx0euH/0930yHIlh+kQ0k6d9z+trt1bHafDtPAhh5RVT80pOiHBtyrwD/e6DV3O8XZXnPrsGVghhOYEI0dwfc8KuvDawJxoYG724dvdgO16hjdXgff9waONZkQjR1FdVDsX6uaDUcwIRpOYEI0nMCEaDiBCdFwAhOi4QQmRMMJTIiGE5gQDScwIRpOYEI0nMCEaDiBCdFwAhOi4QQmRMMJTIiGE5gQDScwIRpOYEI0nMCEaDiBCdFwAhOi4QQmRMMJTIiGE5gQDScwIRpOYEI0nMCEaDiBCdFwgs1EnrpeRB4VkWdF5BkR+WiYb9GnjK1jE/tbzwG3h+kp4DngVuDXgGNh/jHgE2H6XuDPCPbTvhM4bnto2xEdQzWwmc3WM6L5IvBe4CQwlxDryTD9u8CHEvfH95kQ7RimgStqI4rIjcA7gONsQfQpw4jYdJwVEZkE/hj4BVVdlkTsj6uJPiUi9xMEjjSMzXlEEakSiPAPVfXzYfa5KODj1USfUtUHVPUOVb3jao03isNmes0C/D7wLVX99URRFH0KLo0+9eGw93wnFn3K2AQbbuYuIncDXyOIJOWH2b9M0E78HHAD8DLw06p6MRTubxHEeF4Hfk5VLxuBdDdt5t6oT3DjkTdveRjHntfjxVPP4vneFr/y1jJsM3eLKrDD7J3cz3t+5sPM/uSdVGt1qrUalWqVUqlMr9el1+0gCJ7n0e206bSbdNot2q0m7VYzuG61wvw23W4br91l6olVjn/9Ybq9Tt4f8bIME+I1h8k1rpyxA3s5dNet1OpjVKp11Pfodrt0IrG11mmtr9Fa92mud2iuNWmxSkvXaHrrdCrrdL02PemiNYWGz0Q57091bZgQc0BEKJVKiJQQkXCAzUd9H9/z6PV6gXfsdeh1uvS6bbrdDt1OJ8jr9eh5XXwvrIaDAeFcP9O1YnPNDqDhP4oGAcQJI9cP0NaoNmKmpw5QKVeHlpsQ8yLbVBLiuMyayBpR3V3Cm65/G1MHDwwtNyHmhcT/xOf0VcSgoLqjJ08plahOTw4tNyHmhUbTryBBvRykNT05CxJX1Vs95LPTJGfjslhnJQd63S6rK0tU2y0qlSqe16PXadNpt8NhmnVazXXarXU6nWbQSel28bwevu/jwpDbVmNCzIEzzz3Htz/1nbB2FtBE9Rul4zztd2TCXk1JoZaonkWh5DPSmBB3mE63TevFefa1DtKZ2prXbFxQzp85h++PrhpNiDtMs73GqfnvcPPfvAl95wz1xjj1sQa1sQa12hiVWg1Uw1mVVlxVt5vBQHe73aLbaafGEA8/prx0+tt4fi/fD3cNmBBzYmx8kr2Hj7Jn3wx7pvczOb2fycm9jI1PoOrTXFthdXmJlcWLLC9eCM5LC8jyIr7n9YU4Ugxv21qvOU9SnUgl0SoMUnFXORzeiUa+R7D/7Pseq0uLQ8tNiLkTegnNDtBIYmRb0+cRHEdst5qUlrtDy02IeRK5PiEUmWYKE6QGwEePb3/3SXxveGfKhJgnEqpQA++XllniSoXoQbdRxd/AdhNiniiJ6lb6mVFbMPKC4T2XmZgYeUyITqDBNF/iun9SJJzmG+WqeSNMiLki/VPS3UnYcQk9okZdaNVEd7pYmBBzpe/5+u0/SRdr4iLuWI9uW3EYJkRnSYgtaivGWjWPaGwpiao5udAr6fAkseghEuAI956HYULMk9jTJQWZKMxeD0gWBROiE0RtxbBRmBWaRL1qTd1eJEyIeaLZi8w0X9xbJpFfQHeICdEx0g8JxG1CSfrD0Vz0sBEmRBcIHaEmL6DvMRMD20UUIZgQcyZRN2u2So4SfXlmBhYLhQkxV8Inl7V/NZjUeM62WpQXJsQ8SS3tyg5gR9nZscZiekUTYp7EK64j+ksb4lQ0nJjSX/G8ogkxT5IeMTGHrJmUXjIDUzxMiHmiSW1lBTZgEQQEg96juhPTZTAh5oomHpyPmoMDFsomR21EithENCHmSqpTogMeoIoLM+fisZnN3MdE5Bsi8tdhCLRfCfNvEpHjYaiz/y4itTC/Hl6/EJbfuM2fYXTJLHId2vrTpBfcvTMrbeA9qnob8HbgnjBawCeA31DVm4EF4L7w/vuAhTD/N8L7jGEkFsQO9Hdhzzo961I8z7ihEDVgNbyshocC7wH+KMz/DPCBMP3+8Jqw/IfkcvuR7WZEEotck6trBsw3x/cUk80G/CmLyJMEQX0eAV4EFlU12mwlGeYsDoEWli8BMwNe834ReVxELhv6otDokIo5Ft+AFTcFXBQLmxSiqnqq+naCKFLvAt56rW9skacCNJGSTE5yNU7Rq5Qr6jWr6iLwKHAXMC0i0SZOyTBncQi0sHwvcGErjC0kQ6eRE95QJD18U0A202s+KCLTYbpBECL3WwSC/Knwto+QDoH2kTD9U8Bf6ChvUbDtJMYNs99SNK5Y4MdIIzazLd0c8BkRKRMI93Oq+iUReRZ4UET+HfBNgnh9hOf/KiIvABeBD26D3cUh6ghH248ke8WJueX+tHQx/6Y3FKKqPkUQozmb/xJBezGb3wL+/pZYtysIPaFmBZhuKwalxRxDBJtZcYTk2GBqApqojagkO9PFE6MJMVeSaxAv/3BUnJscYywQJkQnSIorc1bCFTdhdjEnVkyI+RKqSkDiKb5LPWNBt7tJYULMm3jMWrMZwaVkHrgvqCBNiLmiibBgEqaTR3hX9NxKQUUIJsScyay4GSa0Aq7IzmJCzJNBjzIPzCn2BkxgQsyZ7APNg1ZiS7/9WNDHBMCEmC/RDEo8k5LsMWeeWbkkXSxMiLkTLY4dMMecXDMr6Q5M0TAh5olE0QIG1beaEGR2h4fiCdKEmCealKAmtqFL33P5hmExRGlCzBNJVsXSjyyQXHuYdIaarKuLhQkxT5Jb0Umis3KJk7vcliPFEKUJMXfCGeZEzXxJezDup0T5xaiOk5gQcyUUlWSbgpEHjKb2tCiObygmxNwJPWLyAakgJ91rTjUPi6dKE2KexB6PIc8rJ2ZairkeNsaEmCfab+9pPJWXXLWduX3HDNt5TIh5kngGReINOYd3RIq8c4sJMVf6Db+Bq28ya2SDRwaKOdVnQsyTRFV86VSfhJrTfmclNYRTLEyIeZPoGWfFqElPWPCdHkyILrDZYcICi9GEmCvZ1Q2Z9t9AzRWvWgYTYv7Eg9XZ5wbSbjJY81DM6T0wIbqBJscQB285Eu/TBLbliLHFSGIDzg22HFGJ9mmyXrOx1cS1b3rnL7J5qumd64qnQxNivvS3HIH0iGJMUpfFq5FjTIguoCCXbDnSZzcEFjAh5oomVmknn+ajfxbtbzmSyC4amxZiGOLimyLypfDaIk9dM1GDT1CJvOKgRwaST+8VU4lX4hE/SrCJe4RFntoKRJLjMqSWa2fGEYu6KBY2H/DnKPBjwH8KrwWLPLV1xAtjhw3NCJLwnrt5HPE3gX8B+OH1DBZ5agvJtA0vGdAOFor193svnlfcMKqAiPw4MK+qT4jI396qN1bVB4AHAEpS0kqlulUv7TzlUgV6PtrsorUOXqWFV27S1SrlnqC+T299HW+1hbfaRtc60OwhLQ/peJTb4HUg+QRgtVyjWqnl+rkuh0jpsq3bzcRZeTfwEyJyLzAG7AH+I2HkqdDrDYo8dWqzkaf2TM9w93vevwlTikGpVKayUEYePk1HzrJQEhalhIjEq7BVFVU/OPs+DVXGfJ8ZraFaST3iUppW7v7Rv4vrcZX+8tGHhpZtJs7Kx4CPAYQe8Z+r6j8Qkf9BEFnqQQZHnvorNhl5qn7Dfm7+rZ8N0vU61Yx37HQ7dDqdtOGVCmP1sVSe53s0m81UnpRKjDcaSOLvUVHW19cv+eHGG+OUSunWSrPVxPO8tL1m41XZ+Nh7v8YwNuMRh/FLbFHkqZXWEo+e/FPG6nXmZg8z3hiPyzqdDmfmz7G6thrnlctlZg8eYt/e6TjP8zzOX3idCwsX4zwB9u/bz+zBQylPs7i0xNnz5/B9P753anKSudnDqR9vbX2N0+fOpn48s/HqbVxpLTGMKxKiqn4V+GqY3tLIU/Va+stTVXq9Hmfmz7K6thbfVyqVOHxwlr179sR5vu8zf+E8FxcWUq85s3+GgzMHUl/ewtIi86+fz3x5Uxw+dCj+8lSV9eY6Z86dS/3AZuPW2DiIa/GIW4aIcN3cHI2xBhB8AM/zeO3sadbW1+P7SiIcmZ1jz9RU6ks5e36exaXF1GsenDnAzL79cRWR/PKS1djU5CSHDx2iVq3F9zVbzUu8TK1aMxu3wMZhOCHEWq0Wt1OiL+/V06+x3kx8eaUSRw7PsWey/+X5vs+58MuL2ikiwsy+/czs20+5XI5fc3F5ifnz83iJv+DJiQmOzM5RqVTi+1qtFqfOnKbb7fbtq1a5/sh11Ot1s/EabLxct9kJIZYSvcVer8drZ0+nvrxyuczhQ7OpLy9qyywsLiSePxL2T+/j4MyB+C/YV5/l5RXOnDubalRPjk9w3dx1lBN/6c1Wi1OnT9Ht9eL7arUa188FP7DZeG021qvDh5ecEGKv3eXiS2cBWFhaTLVlABqTk3ilJguv93ty660mFy5eTN1Xq9WoVpTF1fn+a3seZ+fPpb48KZVolPaw/PL5OE+Bc+fn03/BwPRMg/XTi6wn8szGq7PR76Z79knEhbGniRtu0O/5xV/M2wxjm3nmk59k7ZVXBlbQTnjEPeN7+eF3vi9vM4xt5tXxB4aWOSHEWgWOzpTzNsPYZmqXUZstjDWcwIRoOIEJ0XACE6LhBCZEwwlMiIYTmBANJzAhGk5gQjScwIRoOIEJ0XACE6LhBCZEwwlMiIYTmBANJzAhGk5gQjScwIRoOIEJ0XACE6LhBCZEwwlMiIYTmBANJzAhGk5gQjScwIRoOIEJ0XCCzQb8+a6IPC0iT0ZxUURkv4g8IiLPh+d9Yb6IyKfCEGhPicjt2/kBjGJwJR7x76jq21X1jvD6GPAVVb0F+Ep4DfA+4JbwuB/4na0y1igu11I1J0OdZUOg/YEGfJ0gHsvcNbyPsQvYrBAV+F8i8oSI3B/mzarqmTB9FpgN03EItJBkeLSYZAi01YWL2WJjl7HZ/RHvVtXXROQQ8IiIfDtZqKoqIle09WwyBNobvvf78t+21siVTXlEVX0tPM8DXyCIr3IuqnLDc7ThchQCLSIZHs0wBrKhEEVkQkSmojTwI8AJ+qHO4NIQaB8Oe893AkuJKtwwBrKZqnkW+EIYDqEC/DdV/Z8i8hjwORG5D3gZ+Onw/i8D9wIvAOvAz2251UbhcCKqgIisACfztmOTHABez9uITeCinW9Q1YODCpzYzB04mRifdBoReXwUbB0VOyNsis9wAhOi4QSuCHF4JBj3GBVbR8VOwJHOimG44hGNXU7uQhSRe0TkZLhs7NjG/2Nbbfm0iMyLyIlEnpPL3UTkehF5VESeFZFnROSjLtu7Iaqa2wGUgReBNwI14K+BW3O05weB24ETibxfA46F6WPAJ8L0vcCfEYTDvhM4vsO2zgG3h+kp4DngVlft3fDz5PrmcBfwcOL6Y8DHcrbpxowQTwJziR//ZJj+XeBDg+7Lye4vAu8dFXuzR95V86aWjOXMNS132wlE5EbgHcBxRsDeQeQtxJFCA1fi1DCDiEwCfwz8gqouJ8tctHcYeQtxFJaMObvcTUSqBCL8Q1X9fJjtrL2XI28hPgbcIiI3iUgN+CDBMjKXcHK5mwTLoX4f+Jaq/rrr9m5I3o1Ugt7ccwS953+Zsy2fBc4AXYI21H3ADMHDYc8Dfw7sD+8V4LdDu58G7thhW+8mqHafAp4Mj3tdtXejw2ZWDCfIu2o2DMCEaDiCCdFwAhOi4QQmRMMJTIiGE5gQDScwIRpO8P8BPbqr7ZV5sO0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(587):\n",
    "    \n",
    "    # choose a random action \n",
    "    action = np.random.choice(num_actions)\n",
    "    \n",
    "    # create the corresponding one-hot vector\n",
    "    action_vec = np.zeros(num_actions)\n",
    "    action_vec[action] = 1\n",
    "\n",
    "    # take the action and observe the reward and the next state\n",
    "    image, reward, terminal = game.frame_step(action_vec)\n",
    "\n",
    "    # visualization on Colab\n",
    "    if using_colab and i % 3 == 0:\n",
    "        #  convert from (width, height, channel) to (height, width, channel)\n",
    "        view = image.transpose([1, 0, 2])\n",
    "\n",
    "        #  convert from rgb to bgr\n",
    "        img_bgr = cv2.cvtColor(view, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        #Display image, clear cell output\n",
    "        plt.imshow(img_bgr)\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        # plt.clf()\n",
    "        # plt.imshow(img_bgr)\n",
    "        # output.clear(wait=True)\n",
    "        # cv2_imshow(img_bgr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are you able to see Flappy moving across the window and crashing into things? Great! If you're \n",
    "having any issues, post to EdD and we'll do our best to help you out.\n",
    "\n",
    "Here is how we can visualize a frame of the game as an image within a cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image.transpose([1, 0, 2]))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the images \n",
    "\n",
    "Alright, next we need to prepocess the images by converting them to grayscale and resizing them to $80\\times 80$ pixels. This will help \n",
    "to reduce the computation, and aid learning. Besides, Flappy is \n",
    "\"color blind.\" (Fun fact: The instructor of this course is also \n",
    "[color vision deficient](https://en.wikipedia.org/wiki/Color_blindness).)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the transformed image: (80, 80, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def resize_gray(frame):\n",
    "    frame = cv2.cvtColor(cv2.resize(frame, (80, 80)), cv2.COLOR_BGR2GRAY)\n",
    "    ret, frame = cv2.threshold(frame, 1, 255, cv2.THRESH_BINARY)\n",
    "    return np.reshape(frame, (80, 80, 1))\n",
    "\n",
    "image_transformed = resize_gray(image)\n",
    "print('Shape of the transformed image:', image_transformed.shape)\n",
    "\n",
    "# show the transformed image\n",
    "_ = plt.imshow(image_transformed.transpose((1, 0, 2))[:, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the preprocessed image for a single frame of\n",
    "the game. In our implementation of Deep Q-Learning, we encode the state by stacking four consecutive frames, resulting in \n",
    "a tensor of shape (80,80,4). \n",
    "\n",
    "Then, given the `current_state`, and a raw image `image_raw`\n",
    "of size $288\\times512\\times3$, we convert \n",
    "the raw image to a $80\\times80\\times 1$ grayscale image using the\n",
    "code in the previous cell. The , \n",
    "we remove the first frame of `current_state` and add \n",
    "the new frame, giving again a stack of images of \n",
    "size (80, 80, 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image_raw, current_state=None):\n",
    "    # resize and convert to grayscale\n",
    "    image = resize_gray(image_raw)\n",
    "    # stack the frames\n",
    "    if current_state is None:\n",
    "        state = np.concatenate((image, image, image, image), axis=2)\n",
    "    else:\n",
    "        state = np.concatenate((image, current_state[:, :, :3]), axis=2)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Explain the game state\n",
    "\n",
    "Why is the state chosen to be a stack of four consecutive\n",
    "frames rather than a single frame? Give an intuitive explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "Using a stack of 4 frames as input will catch more temporal information such as the velocity and acceleration, which will be helpful for the network optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Constructing the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to construct the neural network for approximating the Q function. Recall that, given input $s$ which is of size $80\\times80\\times4$ due to the \n",
    "previous preprocessing, the output of the network should be of size 2, corresponding to the values of $Q(s,a_1)$ and $Q(s, a_2)$ respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the summary of the model we'd like to build:\n",
    "\n",
    "![Neural network](https://raw.githubusercontent.com/YData123/sds365-sp22/main/assignments/assn4/images/q_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Initialize the network\n",
    "\n",
    "Complete the code in the next cell so that your model architecture matches that in the above picture. Here we specify the initialization of the weights by using `keras.initializers`.\n",
    "Note that we haven't talked about the `strides` argument for CNNs; \n",
    "you can read about stride here: [https://machinelearningmastery.com/padding-and-stride-for-convolutional-neural-networks/](https://machinelearningmastery.com/padding-and-stride-for-convolutional-neural-networks/). It's not important to understand this in detail, you just need to choose the number and sizes of the filters to get the shapes to match the specification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import initializers\n",
    "def create_q_model():\n",
    "    state = layers.Input(shape=(80, 80, 4,))\n",
    "\n",
    "    layer1 = layers.Conv2D(filters=32, kernel_size=5, strides=4, activation=\"relu\",\n",
    "                           kernel_initializer=initializers.TruncatedNormal(mean=0., stddev=0.01),\n",
    "                           bias_initializer=initializers.Constant(0.01))(state)\n",
    "    layer2 = layers.MaxPool2D(2, strides=2, padding=\"SAME\")(layer1)\n",
    "    layer3 = layers.Conv2D(filters=64, kernel_size=3, strides=2, activation=\"relu\", \n",
    "                           kernel_initializer=initializers.TruncatedNormal(mean=0., stddev=0.01),\n",
    "                           bias_initializer=initializers.Constant(0.01))(layer2)\n",
    "    layer4 = layers.Flatten()(layer3)\n",
    "    q_value = layers.Dense(units=2, activation=\"linear\", \n",
    "                           kernel_initializer=initializers.TruncatedNormal(mean=0., stddev=0.01),\n",
    "                           bias_initializer=initializers.Constant(0.01))(layer4)\n",
    "\n",
    "    return keras.Model(inputs=state, outputs=q_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the model summary to make sure that the network is the same as expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 80, 80, 4)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 19, 19, 32)        3232      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 23,778\n",
      "Trainable params: 23,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = create_q_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Q-learning\n",
    "\n",
    "We're now ready to implement the Q-learning algorithm.\n",
    "There are some subtle details in the implementation that you need to sort out. First, recall that the update rule for Q learning is\n",
    "\n",
    "$$Q(s,a) \\leftarrow Q(s,a) + \\alpha (r(s,a) + \\gamma\\cdot \\max_{a'} Q(\\text{next}(s,a), a') - Q(s,a))$$\n",
    "\n",
    "where $\\gamma$ is the discount factor and $\\alpha$ can be viewed as the step size or learning rate for gradient ascent.\n",
    "\n",
    "We'll set these as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.99            # decay rate of past observations\n",
    "step_size = 1e-4        # step size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation with experience replay\n",
    "\n",
    "At the beginning of training, we spend 10,000 steps taking random \n",
    "actions, as a means of observing the environment. \n",
    "\n",
    "We build a replay memory of length 10,000 steps, and every time we update the weights of the network, we sample a batch of size 32 and perform a Q-learning update on this batch.\n",
    "\n",
    "After we have collected 10,000 steps of new data, we discard \n",
    "the old data, and replace it with the new \"experiences.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "observe = 10000            # timesteps to observe before training\n",
    "replay_memory = 10000      # number of previous transitions to remember\n",
    "batch_size = 32            # size of each batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3.3 Justify the data collection\n",
    "\n",
    "Why does it make sense to maintain the replay memory of a fixed size \n",
    "instead of including all of the historical data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "Including all of the historical data will result in a significant amount of memory usage as the training progresses. The historical data very long time ago might also have little influence on the current training scheme. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration vs exploitation\n",
    "\n",
    "When performing Q-learning, we face the tradeoff between exploration and \n",
    "exploitation.  To encourage exploration, a simple strategy is to take a random action at each step with certain probability.\n",
    "\n",
    "More precisely, for each time step $t$ and state $s_t$, with probability $\\epsilon$, the algorithm takes a random action (wing flap or do nothing), and with probability $1-\\epsilon$ the \n",
    "algorithm takes a greedy action according to $a_t = \\arg\\max_{a} Q_\\theta(s_t,a)$. Here $\\theta$ refers to the parameters of our CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value of epsilon\n",
    "epsilon = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Complete the Q-learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you will need to complete the Q-learning algorithm by filling in the missing code in the following function.\n",
    "The missing parts include\n",
    "\n",
    "- Taking a greedy action\n",
    "- Given a batch of samples $\\{(s_t, a_t, r_t, s_{t+1}, \\text{terminal}_t)\\}_{t\\in B}$, computing the corresponding $Q_\\theta(s_t, a_t)$.\n",
    "- Given a batch of samples $\\{(s_t, a_t, r_t, s_{t+1}, \\text{terminal}_t)\\}_{t\\in B}$, computing the corresponding updated Q-values \n",
    "  \n",
    "$$\\hat{y}(s_t,a_t) = \\begin{cases}\n",
    "r_t + \\gamma\\, \\max_{a} Q_\\theta(s_{t+1}, a), & \\text{if } \\text{terminal}_t=0,\\\\\n",
    "r_t, & \\text{otherwise}.\n",
    "\\end{cases}$$\n",
    "\n",
    "Then, the mean squared error loss for the batch is\n",
    "\n",
    "$$\\frac{1}{|B|} \\sum_{t\\in B} (\\hat y(s_t, a_t) - Q_\\theta(s_t, a_t))^2.$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dql_flappy_bird(model, optimizer, loss_function):\n",
    "\n",
    "    # initiate a game\n",
    "    game = flappy_bird.GameState()\n",
    "\n",
    "    # store the previous state, action and transitions\n",
    "    history_data = deque()\n",
    "\n",
    "    # get the first observation by doing nothing and preprocess the image\n",
    "    do_nothing = np.zeros(num_actions)\n",
    "    do_nothing[0] = 1\n",
    "    image, reward, terminal = game.frame_step(do_nothing)\n",
    "\n",
    "    # preprocess to get the state\n",
    "    current_state = preprocess(image_raw=image)\n",
    "    \n",
    "    # training\n",
    "    t = 0\n",
    "\n",
    "    while t < 50000:\n",
    "        if epsilon > np.random.rand(1)[0]:\n",
    "            # random action\n",
    "            action = np.random.choice(num_actions)\n",
    "        else:\n",
    "            # compute the Q function\n",
    "            current_state_tensor = tf.convert_to_tensor(current_state)\n",
    "            current_state_tensor = tf.expand_dims(current_state_tensor, 0)\n",
    "            q_value = model(current_state_tensor, training=False)\n",
    "            \n",
    "            # greedy action\n",
    "            #-----MISSING-----# \n",
    "            # your code here\n",
    "            action = np.argmax(q_value)\n",
    "            #-----------------#\n",
    "\n",
    "        # take the action and observe the reward and the next state\n",
    "        action_vec = np.zeros([num_actions])\n",
    "        action_vec[action] = 1\n",
    "        image_raw, reward, terminal = game.frame_step(action_vec)\n",
    "        next_state = preprocess(current_state=current_state, \n",
    "                                image_raw=image_raw)\n",
    "        \n",
    "        # store the observation\n",
    "        history_data.append((current_state, action, reward, next_state, \n",
    "                            terminal))\n",
    "        if len(history_data) > replay_memory:\n",
    "            history_data.popleft()  # discard old data\n",
    "\n",
    "        # train if done observing\n",
    "        if t > observe:\n",
    "\n",
    "            # sample a batch\n",
    "            batch = random.sample(history_data, batch_size)\n",
    "            state_sample = np.array([d[0] for d in batch]) # (32, 80, 80, 4)\n",
    "            action_sample = np.array([d[1] for d in batch]) # (32,)\n",
    "            reward_sample = np.array([d[2] for d in batch]) # (32,)\n",
    "            state_next_sample = np.array([d[3] for d in batch]) # (32, 80, 80, 4)\n",
    "            terminal_sample = np.array([d[4] for d in batch]) # (32,)\n",
    "\n",
    "            # compute the updated Q-values for the samples\n",
    "            #-----MISSING-----#\n",
    "            # your code here\n",
    "            # print(state_sample)\n",
    "            # print(state_sample.shape)\n",
    "            # print(action_sample.shape)\n",
    "            # print(reward_sample.shape)\n",
    "            # print(state_next_sample.shape)\n",
    "            # print(terminal_sample.shape)\n",
    "\n",
    "            updated_q_value_list = []\n",
    "            for i in range(batch_size):\n",
    "                if terminal_sample[i]:\n",
    "                    updated_q_value_list.append(reward_sample[i])\n",
    "                else:\n",
    "                    current_q_table = model(state_next_sample, training=False)\n",
    "                    updated_q_value_list.append(reward_sample[i] + gamma*np.max(current_q_table[i]))\n",
    "\n",
    "            updated_q_value = tf.convert_to_tensor(updated_q_value_list)\n",
    "            # print(updated_q_value)\n",
    "            #-----------------#\n",
    "\n",
    "            # train the model on the states and updated Q-values\n",
    "            with tf.GradientTape() as tape:\n",
    "                # compute the current Q-values for the samples\n",
    "                #-----MISSING-----#\n",
    "                # your code here\n",
    "                current_q_table = model(state_sample, training=False)\n",
    "                current_q_value = tf.convert_to_tensor([current_q_table[i, action_sample[i]] for i in range(batch_size)])\n",
    "                # print(current_q_value)\n",
    "                #-----------------#\n",
    "\n",
    "                # compute the loss\n",
    "                loss = loss_function(updated_q_value, current_q_value)\n",
    "\n",
    "            # backpropagation\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        else:\n",
    "            loss = 0\n",
    "\n",
    "        # update current state and counter\n",
    "        current_state = next_state\n",
    "        t += 1\n",
    "\n",
    "        # print info every 500 steps\n",
    "        if using_colab and t % 3 == 0: # previous every 3 steps\n",
    "            view = image_raw.transpose([1, 0, 2])\n",
    "            img_bgr = cv2. cvtColor(view, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            display.clear_output(wait=True)\n",
    "            # output.clear(wait=True)\n",
    "            print(f\"STEP {t} | PHASE {'observe' if t<=observe else 'train'}\", \n",
    "                  f\"| ACTION {action} | REWARD {reward} | LOSS {loss}\")\n",
    "            plt.imshow(img_bgr)\n",
    "            display.display(plt.gcf())\n",
    "            # cv2_imshow(img_bgr)\n",
    "        elif t % 500 == 0:\n",
    "            print(f\"STEP {t} | PHASE {'observe' if t<=observe else 'train'}\", \n",
    "                  f\"| ACTION {action} | REWARD {reward} | LOSS {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're now ready to play the game! Just run the cell below; do not change the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playgame(start_from_ckpt=False, ckpt_path=None):\n",
    "\n",
    "    #! DO NOT change the random seed !\n",
    "    np.random.seed(4)\n",
    "\n",
    "    if start_from_ckpt:\n",
    "        # if you want to start from a checkpoint\n",
    "        model = keras.models.load_model('ckpt_path')\n",
    "    else:\n",
    "        model = create_q_model()\n",
    "\n",
    "    # specify the optimizer and loss function\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=step_size, clipnorm=1.0)\n",
    "    loss_function = keras.losses.MeanSquaredError()\n",
    "\n",
    "    # play the game\n",
    "    dql_flappy_bird(model=model, optimizer=optimizer, loss_function=loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 201 | PHASE observe | ACTION 0 | REWARD 0.1 | LOSS 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-fb53a04cedc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplaygame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-ac00ff68e08b>\u001b[0m in \u001b[0;36mplaygame\u001b[0;34m(start_from_ckpt, ckpt_path)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# play the game\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdql_flappy_bird\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-53-d50c971e8299>\u001b[0m in \u001b[0;36mdql_flappy_bird\u001b[0;34m(model, optimizer, loss_function)\u001b[0m\n\u001b[1;32m    113\u001b[0m                   f\"| ACTION {action} | REWARD {reward} | LOSS {loss}\")\n\u001b[1;32m    114\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_bgr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0;31m# cv2_imshow(img_bgr)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2191\u001b[0m                            else suppress())\n\u001b[1;32m   2192\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2193\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2195\u001b[0m                     bbox_inches = self.figure.get_tightbbox(\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1864\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m                          \u001b[0;32melse\u001b[0m \u001b[0mdeprecation_addendum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                 **kwargs)\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2745\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2747\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2749\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m             im, l, b, trans = self.make_image(\n\u001b[0;32m--> 644\u001b[0;31m                 renderer, renderer.get_image_magnification())\n\u001b[0m\u001b[1;32m    645\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mmake_image\u001b[0;34m(self, renderer, magnification, unsampled)\u001b[0m\n\u001b[1;32m    927\u001b[0m                 else self.figure.bbox)\n\u001b[1;32m    928\u001b[0m         return self._make_image(self._A, bbox, transformed_bbox, clip,\n\u001b[0;32m--> 929\u001b[0;31m                                 magnification, unsampled=unsampled)\n\u001b[0m\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_unsampled_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_make_image\u001b[0;34m(self, A, in_bbox, out_bbox, clip_bbox, magnification, unsampled, round_to_pixel_border)\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_scalar_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                 output_alpha = _resample(  # resample alpha channel\n\u001b[0;32m--> 553\u001b[0;31m                     self, A[..., 3], out_shape, t, alpha=alpha)\n\u001b[0m\u001b[1;32m    554\u001b[0m                 output = _resample(  # resample rgb channels\n\u001b[1;32m    555\u001b[0m                     self, _rgb_to_rgba(A[..., :3]), out_shape, t, alpha=alpha)\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_resample\u001b[0;34m(image_obj, data, out_shape, transform, resample, alpha)\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                     \u001b[0mimage_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_filternorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                     image_obj.get_filterrad())\n\u001b[0m\u001b[1;32m    198\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "playgame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Describe the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe what you see by answering the following questions:\n",
    "\n",
    "- In the early stage of training (within 2,000 steps in the *explore* phase), \n",
    "  describe the behavior of the Flappy Bird. What do you think is the greedy policy \n",
    "  given by the estimation of the Q-function in this stage?\n",
    "- Describe what you see after roughly 5,000 training steps. \n",
    "  Do you see any improvement?\n",
    "  In particular, compare Flappy's behavior with their behavior in the early stages of \n",
    "  training.\n",
    "- Explain why the performance has improved, by relating to the model \n",
    "  design such as the replay memory and the exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer;\n",
    "- In the early stage of the training, the flappy bird crashes frequently. The greedy policy given by the estimation of the Q-function seems to be a random policy.\n",
    "- After roughly 5000 training steps, there are some improvement. The bird seems to be able to avoid some obstacles and the episode seems to be longer.\n",
    "- As in the early stage, the content in the replay buffer is mostly constructed in the observation stage. As the training progresses, the model is able to exploit and explore following the epsilon-greedy policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes a long time to fully train the network, so you're not required to \n",
    "complete the training. Here's a [video](https://www.youtube.com/watch?v=THhUXIhjkCM) showing the performance of a well trained DQN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Julius Tensor (15 points)\n",
    "\n",
    "In this problem you will modify a basic vanilla \"np-complete\" implementation of recurrent neural networks, and evaluate some pre-trained RNNs trained on the plays of \n",
    "William Shakespeare.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_shakespeare(model, size=1000, seed='ROMEO:'):\n",
    "    states = None\n",
    "    next_char = tf.constant([seed])\n",
    "    result = [next_char]\n",
    "                             \n",
    "    for n in range(1000):\n",
    "      next_char, states = model.generate_one_step(next_char, states=states)\n",
    "      result.append(next_char)\n",
    "\n",
    "    return tf.strings.join(result)[0].numpy().decode(\"utf-8\")\n",
    "                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.1: Word play\n",
    "\n",
    "We have upload three pre-trained models for you to experiment with: 'Hamlet', 'Macbeth', and 'Comedy of Errors'. One of the models has 256 hidden neurons in the GRU layer, and was trained\n",
    "for 30 epochs. The two other models each have have 1024 hidden neurons in the GRU layer; one was trained for 30 epochs, and the other trained for 50 epochs. \n",
    "\n",
    "Generate sample text from each, using the function `generate_shakespeare` defined above, in order to evaluate the models. Which model is which? Explain how you made your assessment.\n",
    "\n",
    "You can download the models 'Hamlet', 'Comedy_of_Errors' and 'Macbeth' from \n",
    "https://github.com/YData123/sds365-sp22/tree/main/assignments/assn4.\n",
    "\n",
    "Note: If you are unable to load and run these models on your own computer, please run \n",
    "them in the cloud on Colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "def func_unzip(path_to_zip_file, directory_to_extract_to):\n",
    "    with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(directory_to_extract_to)\n",
    "\n",
    "func_unzip('Hamlet.zip','Hamlet_unzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The same saveable will be restored with two names: ids_from_chars/_table/.ATTRIBUTES/table",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-c67084e1f46c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpretrained1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Hamlet_unzip/Hamlet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# pretrained2 = tf.saved_model.load('Comedy_of_Errors')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# pretrained3 = tf.saved_model.load('Macbeth')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags, options)\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0ma\u001b[0m \u001b[0mMetaGraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSavedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m   \"\"\"\n\u001b[0;32m--> 603\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, options, loader_cls)\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         loader = loader_cls(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0;32m--> 633\u001b[0;31m                             ckpt_options)\n\u001b[0m\u001b[1;32m    634\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         raise FileNotFoundError(\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m_restore_checkpoint\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m                                   self._checkpoint_options).expect_partial()\n\u001b[1;32m    329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m       \u001b[0mload_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m     \u001b[0mload_status\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_existing_objects_matched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_status\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   1318\u001b[0m         options=options)\n\u001b[1;32m   1319\u001b[0m     base.CheckpointPosition(\n\u001b[0;32m-> 1320\u001b[0;31m         checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root)\n\u001b[0m\u001b[1;32m   1321\u001b[0m     load_status = CheckpointLoadStatus(\n\u001b[1;32m   1322\u001b[0m         \u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, trackable)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;31m# This object's correspondence with a checkpointed object is new, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;31m# process deferred restorations for it and its dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mrestore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_from_checkpoint_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestore_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_restore_from_checkpoint_position\u001b[0;34m(self, checkpoint_position)\u001b[0m\n\u001b[1;32m    912\u001b[0m     restore_ops.extend(\n\u001b[1;32m    913\u001b[0m         current_position.checkpoint.restore_saveables(\n\u001b[0;32m--> 914\u001b[0;31m             tensor_saveables, python_saveables))\n\u001b[0m\u001b[1;32m    915\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mrestore_saveables\u001b[0;34m(self, tensor_saveables, python_saveables)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtensor_saveables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m       validated_saveables = saveable_object_util.validate_and_slice_inputs(\n\u001b[0;32m--> 290\u001b[0;31m           tensor_saveables)\n\u001b[0m\u001b[1;32m    291\u001b[0m       \u001b[0mvalidated_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaveable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msaveable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidated_saveables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_saveables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mvalidated_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/tensorflow/python/training/saving/saveable_object_util.py\u001b[0m in \u001b[0;36mvalidate_and_slice_inputs\u001b[0;34m(names_to_saveables)\u001b[0m\n\u001b[1;32m    359\u001b[0m                          key=lambda x: x[0]):\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mconverted_saveable_object\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msaveable_objects_for_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m       \u001b[0m_add_saveable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaveables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseen_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverted_saveable_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msaveables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_env/lib/python3.6/site-packages/tensorflow/python/training/saving/saveable_object_util.py\u001b[0m in \u001b[0;36m_add_saveable\u001b[0;34m(saveables, seen_ops, saveable)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msaveable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseen_ops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     raise ValueError(\"The same saveable will be restored with two names: %s\" %\n\u001b[0;32m--> 331\u001b[0;31m                      saveable.name)\n\u001b[0m\u001b[1;32m    332\u001b[0m   \u001b[0msaveables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaveable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0mseen_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaveable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The same saveable will be restored with two names: ids_from_chars/_table/.ATTRIBUTES/table"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "pretrained1 = tf.saved_model.load('./Hamlet_unzip/Hamlet')\n",
    "# pretrained2 = tf.saved_model.load('Comedy_of_Errors')\n",
    "# pretrained3 = tf.saved_model.load('Macbeth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code and markdown here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.2: np-complete implementation of RNNs\n",
    "\n",
    "Run the [basic rnn code](https://github.com/YData123/sds365-sp22/blob/main/assignments/assn4/shakespeare_rnn.py) from [Andrej Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) to train a model on the [Shakespeare data](https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt). \n",
    "Modify the code however you see fit, for example, by changing how often a snippet of synthetic text is generated.\n",
    "\n",
    "* How many steps of gradient descent did you train for? How many characters of Shakespeare data was processed during training? How long did the training take?\n",
    "\n",
    "* Did you modify the code in any way? If so, how?\n",
    "\n",
    "* Provide a few examples of generated text from your trained model.\n",
    "\n",
    "* How do the generated samples compare to those generated\n",
    "in Problem 4.1?\n",
    "\n",
    "* Describe at least three differences between this vanilla RNN model\n",
    "and the GRU networks that you experimented with in 4.1, which are described [here](https://www.tensorflow.org/text/tutorials/text_generation).\n",
    "\n",
    "Note: To limit the output the graders need to examine, please experiment in a separate Python session, and only include your final results in this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code and markdown here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.3: Adding a layer \n",
    "\n",
    "Now suppose you wish to add another recurrent hidden layer to the np-complete RNN implementation. Rather than implementing the full model training, \n",
    "we'd like you to implement the generator. (But we encourage you to at least partially implement the full training of the two-layer model.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the generator for the model that has a single recurrent layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(h, seed_ix, n):\n",
    "    \"\"\"\n",
    "    sample a sequence of integers from the model\n",
    "    h is memory state, seed_ix is a seed letter for first time step\n",
    "    \"\"\"\n",
    "    x = np.zeros((vocab_size, 1))\n",
    "    x[seed_ix] = 1\n",
    "    ixes = []\n",
    "    for t in range(n):\n",
    "        h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
    "        y = np.dot(Why, h) + by\n",
    "        p = np.exp(y) / np.sum(np.exp(y))\n",
    "        ix = np.random.choice(range(vocab_size), p=p.ravel())\n",
    "        x = np.zeros((vocab_size, 1))\n",
    "        x[ix] = 1\n",
    "        ixes.append(ix)\n",
    "        \n",
    "    return ixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your job is to rewrite this function for a model that has two hidden recurrent layers.\n",
    "Complete the implementation below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample2(h1, h2, seed_ix, n):\n",
    "    \"\"\"\n",
    "    sample a sequence of integers from the model\n",
    "    h1, h2 is memory state, seed_ix is a seed letter for first time step\n",
    "    \"\"\"\n",
    "    x = np.zeros((vocab_size, 1))\n",
    "    x[seed_ix] = 1\n",
    "    ixes = []\n",
    "    for t in range(n):\n",
    "        ...\n",
    "\n",
    "    return ixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain your implementation, by giving a description of each line of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Your markdown here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.4 Be the Bard (optional, 2 points EC)\n",
    "\n",
    "Starting from the [TensorFlow tutorial](https://www.tensorflow.org/text/tutorials/text_generation), train the best model \n",
    "that you can, generating synthetic Shakespeare that is better than the best model\n",
    "from problem 4.1 above. \n",
    "\n",
    "* Describe how the model is indeed better than the best model in 4.1.\n",
    "* Provide details on how you trained the model, and any changes made to the model \n",
    "architecture.\n",
    "* So that you do not add too much stuff to your notebook, put your code in a separate notebook (submitted to Canvas), and only add Markdown below to detail your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Your markdown here]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
